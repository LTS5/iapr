{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Important-notes\" data-toc-modified-id=\"Important-notes-1\">Important notes</a></span></li><li><span><a href=\"#0-Extract-relevant-data\" data-toc-modified-id=\"0-Extract-relevant-data-2\">0 Extract relevant data</a></span></li><li><span><a href=\"#Part-1\" data-toc-modified-id=\"Part-1-3\">Part 1</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.1-Data-visualization\" data-toc-modified-id=\"1.1-Data-visualization-3.1\">1.1 Data visualization</a></span></li><li><span><a href=\"#1.2-Fourier-descriptors-(15-pts)\" data-toc-modified-id=\"1.2-Fourier-descriptors-(15-pts)-3.2\">1.2 Fourier descriptors (15 pts)</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.2.1-Preprocessing\" data-toc-modified-id=\"1.2.1-Preprocessing-3.2.1\">1.2.1 Preprocessing</a></span></li><li><span><a href=\"#1.2.2-Implementation-of-Fourier-descriptors\" data-toc-modified-id=\"1.2.2-Implementation-of-Fourier-descriptors-3.2.2\">1.2.2 Implementation of Fourier descriptors</a></span></li><li><span><a href=\"#1.2.3-Properties-of-Fourier-descriptor\" data-toc-modified-id=\"1.2.3-Properties-of-Fourier-descriptor-3.2.3\">1.2.3 Properties of Fourier descriptor</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.2.3.1-Rotation-invariance\" data-toc-modified-id=\"1.2.3.1-Rotation-invariance-3.2.3.1\">1.2.3.1 Rotation invariance</a></span></li><li><span><a href=\"#1.2.3.2-Translation-invariance\" data-toc-modified-id=\"1.2.3.2-Translation-invariance-3.2.3.2\">1.2.3.2 Translation invariance</a></span></li><li><span><a href=\"#1.2.3.3-Scaling-invariance\" data-toc-modified-id=\"1.2.3.3-Scaling-invariance-3.2.3.3\">1.2.3.3 Scaling invariance</a></span></li></ul></li><li><span><a href=\"#1.2.4-Discussion-on-using-Fourier-descriptors-(TODO)\" data-toc-modified-id=\"1.2.4-Discussion-on-using-Fourier-descriptors-(TODO)-3.2.4\">1.2.4 Discussion on using Fourier descriptors (TODO)</a></span></li></ul></li><li><span><a href=\"#1.3-Additional-method-(5-pts)\" data-toc-modified-id=\"1.3-Additional-method-(5-pts)-3.3\">1.3 Additional method (5 pts)</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.3.1-Ideas\" data-toc-modified-id=\"1.3.1-Ideas-3.3.1\">1.3.1 Ideas</a></span></li><li><span><a href=\"#1.3.2-Utility-function\" data-toc-modified-id=\"1.3.2-Utility-function-3.3.2\">1.3.2 Utility function</a></span></li><li><span><a href=\"#1.3.3-Examples\" data-toc-modified-id=\"1.3.3-Examples-3.3.3\">1.3.3 Examples</a></span></li><li><span><a href=\"#1.3.4-Extract-features-to-cluster-digits\" data-toc-modified-id=\"1.3.4-Extract-features-to-cluster-digits-3.3.4\">1.3.4 Extract features to cluster digits</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.3.4.1-Performance-on-original-images\" data-toc-modified-id=\"1.3.4.1-Performance-on-original-images-3.3.4.1\">1.3.4.1 Performance on original images</a></span></li><li><span><a href=\"#1.3.4.2-Invariant-performance-to-different-transformation\" data-toc-modified-id=\"1.3.4.2-Invariant-performance-to-different-transformation-3.3.4.2\">1.3.4.2 Invariant performance to different transformation</a></span></li></ul></li><li><span><a href=\"#1.3.5-Discussion-on-using-different-methods\" data-toc-modified-id=\"1.3.5-Discussion-on-using-different-methods-3.3.5\">1.3.5 Discussion on using different methods</a></span></li></ul></li></ul></li><li><span><a href=\"#Part-2\" data-toc-modified-id=\"Part-2-4\">Part 2</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.1-Data-visualization\" data-toc-modified-id=\"2.1-Data-visualization-4.1\">2.1 Data visualization</a></span></li><li><span><a href=\"#2.2-Fourier-descriptors---4-digits-(10-pts)\" data-toc-modified-id=\"2.2-Fourier-descriptors---4-digits-(10-pts)-4.2\">2.2 Fourier descriptors - 4 digits (10 pts)</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.2.1-Preprocessing\" data-toc-modified-id=\"2.2.1-Preprocessing-4.2.1\">2.2.1 Preprocessing</a></span></li><li><span><a href=\"#2.2.2-Implementation-of-Fourier-descriptors\" data-toc-modified-id=\"2.2.2-Implementation-of-Fourier-descriptors-4.2.2\">2.2.2 Implementation of Fourier descriptors</a></span></li><li><span><a href=\"#2.2.3-Is-it-possible-to-discriminate-all-these-4-digits-with-a-2-dimensional-feature-vector?\" data-toc-modified-id=\"2.2.3-Is-it-possible-to-discriminate-all-these-4-digits-with-a-2-dimensional-feature-vector?-4.2.3\">2.2.3 Is it possible to discriminate all these 4 digits with a 2-dimensional feature vector?</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IAPR][iapr]: Lab 2 ‒  Object description\n",
    "\n",
    "**Group ID:** 32\n",
    "\n",
    "**Author 1 (350508):** Ziyi ZHAO  \n",
    "**Author 2 (321657):** Yujie HE   \n",
    "**Author 3 (337088):** Xufeng GAO  \n",
    "\n",
    "**Release date:** 25.03.2022  \n",
    "**Due date:** 08.04.2022 (11:59 pm)\n",
    "\n",
    "\n",
    "## Important notes\n",
    "\n",
    "The lab assignments are designed to teach practical implementation of the topics presented during class well as\n",
    "preparation for the final project, which is a practical project which ties together the topics of the course.\n",
    "\n",
    "As such, in the lab assignments/final project, unless otherwise specified, you may, if you choose, use external\n",
    "functions from image processing/ML libraries like opencv and sklearn as long as there is sufficient explanation\n",
    "in the lab report. For example, you do not need to implement your own edge detector, etc.\n",
    "\n",
    "**! Before handling back the notebook <font color='red'> rerun </font>the notebook from scratch !**\n",
    "`Kernel` > `Restart & Run All`\n",
    "\n",
    "We will not rerun the notebook for you.\n",
    "\n",
    "\n",
    "[iapr]: https://github.com/LTS5/iapr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 0 Extract relevant data\n",
    "We first need to extract the `lab-02-data.tar.gz` archive.\n",
    "To this end, we use the [tarfile] module from the Python standard library.\n",
    "\n",
    "[tarfile]: https://docs.python.org/3.6/library/tarfile.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # merge cv2 and cv\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import time\n",
    "import tarfile\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import skimage\n",
    "from skimage import filters, measure, morphology, exposure, color\n",
    "from skimage.transform import rescale\n",
    "from skimage.exposure import histogram, cumulative_distribution, equalize_hist\n",
    "from scipy import ndimage as ndi\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.cluster import KMeans\n",
    "import webcolors\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/lab-02-data.tar.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_367/1475794952.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtar_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_base_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.tar.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r:gz'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_base_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/tarfile.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[1;32m   1619\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCompressionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unknown compression type %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcomptype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"|\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/tarfile.py\u001b[0m in \u001b[0;36mgzopen\u001b[0;34m(cls, name, mode, fileobj, compresslevel, **kwargs)\u001b[0m\n\u001b[1;32m   1665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1667\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1668\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/lab-02-data.tar.gz'"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "data_base_path = os.path.join(os.pardir, 'data')\n",
    "data_folder = 'lab-02-data'\n",
    "data_part1 = os.path.join(data_base_path, data_folder, 'part1')\n",
    "data_part2 = os.path.join(data_base_path, data_folder, 'part2')\n",
    "\n",
    "tar_path = os.path.join(data_base_path, data_folder + '.tar.gz')\n",
    "with tarfile.open(tar_path, mode='r:gz') as tar:\n",
    "    tar.extractall(path=data_base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1\n",
    "In the `lab-02-data/part1` folder, you will find **28x28 grey-scale pictures** of handwritten \"0\" and \"1\".\n",
    "These digits have been extracted from MNIST dataset (http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "Your goal is to extract, from each of those images, a 2-dimensional feature vector (i.e. 2 features) and to plot them all on a 2D graph.\n",
    "If you have chosen good features, the vectors of the \"0\"'s should nicely cluster in one part of the plane and those of the \"1\"'s in another.\n",
    "\n",
    "Please try:\n",
    "1. Fourier Descriptors (15pts). \n",
    "    1. Implementation (10 pts).\n",
    "    2. **Showing invariance to rotation, translation and scaling (5 pts).**\n",
    "2. Additional method of your choice (5 pts)\n",
    "\n",
    "\n",
    "**Note: for the Fourier descriptors, the u_k signal has to be constructed by following the contour point after point. Some pre-processing (image binarization, possibly some Mathematical Morphology) might be useful.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def load(path, digit='0'):\n",
    "    digit_path = os.path.join(path, digit)\n",
    "    digit_names = [nm for nm in os.listdir(digit_path) if '.png' in nm]  # make sure to only load .png\n",
    "    digit_names.sort()  # sort file names\n",
    "    ic = skimage.io.imread_collection([os.path.join(digit_path, nm) for nm in digit_names])\n",
    "    digit_im = skimage.io.concatenate_images(ic)\n",
    "    return digit_im, digit_names\n",
    "                        \n",
    "#  Load zeros and ones\n",
    "zeros_im, zeros_names = load(data_part1, digit='0')\n",
    "ones_im, ones_names = load(data_part1, digit='1')\n",
    "numberOf_im = zeros_im.shape[0]\n",
    "\n",
    "# Plot images\n",
    "fig, axes = plt.subplots(2, len(zeros_im), figsize=(12, 3))\n",
    "for ax, im, nm in zip(axes[0], zeros_im, zeros_names):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n",
    "for ax, im, nm in zip(axes[1], ones_im, ones_names):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot multiple images\n",
    "def plotMultipleImages(nrows, ncols, images, titles, cmap, figsize_x=14, figsize_y=7, suptitle=None):\n",
    "    fig = plt.figure(figsize=(figsize_x,figsize_y))\n",
    "    fig.suptitle(t=suptitle, y=0.63)\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.3)\n",
    "    for i in range(len(titles)):\n",
    "        ax = fig.add_subplot(nrows, ncols, i+1)\n",
    "        if cmap[i]=='rgb':\n",
    "            ax.imshow(images[i])\n",
    "        else:\n",
    "            ax.imshow(images[i], cmap=cmap[i])\n",
    "        ax.set_title(titles[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Fourier descriptors (15 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Preprocessing\n",
    "\n",
    "Input image must be segmented and boundary of the object must be found out before calculating the Fourier Descriptors. Thus, appropriate image preprocessing methods are considered. \n",
    "- A low-pass filter should be used to filter out unnecessary informations that may lead to misclassification of numbers. Here, we select the `median filter` due to its main advantages: I) Median filtering preserves sharp contours which are quite important bases in Fourier descriptors, whereas linear low-pass filtering blurs such edges. II) Median filters are very efficient for smoothing of spiky noise.\n",
    "- We check the histogram distribution of input image and found it is nicely bimodal. The two peaks (intensities of 0 and 255) correspond to the background and handwritten digits, and a few pixels lie in the range between 0 and 255. We then binariz the input images with thresholding to select areas of interest of images (here the digits). Because the input images are in different histrogram ditributions, a global threholding might not be good in all cases. Here, we use `Otsu's method` which determines an optimal global threshold value from the image histogram automatically.\n",
    "- After that, we use `morphological opening` to remove some white patches caused by residual noise (can be found in 1_8.png).\n",
    "- Finally, function `find_countours` is used to detect the contours of objects. And the returned value is a list of the coordinates of the contour pixels in order, going **counterclocwise** around the shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we just show the bimodel of histogram distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test image\n",
    "ind = 7\n",
    "test_im = ones_im[ind]\n",
    "test_im_name = ones_names[ind]\n",
    "\n",
    "# check the histrogram ditribution\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(test_im, cmap='gray')\n",
    "ax[0].set_title(test_im_name)\n",
    "ax[0].axis('off') \n",
    "ax[1].hist(test_im.ravel(), bins=256) \n",
    "ax[1].set_title('256 bins historgram of '+test_im_name)\n",
    "ax[1].set_xlabel('Pixel intensity')\n",
    "ax[1].set_ylabel('Number of pixels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ordered_contour(in_im):\n",
    "    # a list of the coordinates of the contour pixels (float type)\n",
    "    \n",
    "    contours = measure.find_contours(in_im, 5)\n",
    "    ordered_contour = []\n",
    "    contour_im = np.zeros(in_im.shape).astype(np.uint8)\n",
    "    contour_len = []\n",
    "    for contour in contours:\n",
    "        contour_len.append(contour.shape[0])\n",
    "        contour = np.rint(contour).astype(np.uint8)\n",
    "        for x,y in contour:\n",
    "            ordered_contour.append((x,y))\n",
    "            contour_im[x,y] = 255\n",
    "    #print(contour_len)\n",
    "    return contours, np.array(ordered_contour).astype(int), contour_im\n",
    "\n",
    "def pre_processing(in_im, thresh=5):\n",
    "    # De-noise\n",
    "    # median filter with kernel = 1\n",
    "    \n",
    "    median_im = cv.medianBlur(in_im, 1)\n",
    "\n",
    "    # Image binarization\n",
    "    # Otsu's thresholding\n",
    "    _,binary_im = cv.threshold(median_im, 0, 255, cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "\n",
    "    # Morphological opening\n",
    "    morph_im = skimage.morphology.diameter_opening(binary_im,thresh)\n",
    "    \n",
    "    # get the orderred contours\n",
    "    contours, ordered_contour, contour_im = get_ordered_contour(morph_im)\n",
    "    \n",
    "    return median_im, binary_im, morph_im, contours, contour_im, ordered_contour \n",
    "\n",
    "def collect_contours_forAll(numberOf_im, zeros_im, ones_im, thresh=5):\n",
    "    # compute the contour coordinates\n",
    "    zeros_contour = []\n",
    "    ones_contour = []\n",
    "    zeros_contour_im = np.zeros(zeros_im.shape).astype(np.uint8)\n",
    "    ones_contour_im = np.zeros(ones_im.shape).astype(np.uint8)\n",
    "    for ind, zeros, ones in zip(range(numberOf_im), zeros_im, ones_im):\n",
    "        _, _, _, _, contour_im, ordered_contour = pre_processing(zeros)\n",
    "        zeros_contour_im[ind] = contour_im\n",
    "        zeros_contour.append(ordered_contour)\n",
    "        _, _, _, _, contour_im, ordered_contour = pre_processing(ones, thresh)\n",
    "        ones_contour_im[ind] = contour_im\n",
    "        ones_contour.append(ordered_contour)\n",
    "    return zeros_contour, ones_contour, zeros_contour_im, ones_contour_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_contour, ones_contour, zeros_contour_im, ones_contour_im = collect_contours_forAll(numberOf_im, zeros_im, ones_im)\n",
    "# display the plots\n",
    "plotMultipleImages(1, 10, zeros_im, zeros_names, cmap=['gray']*10, figsize_x=20, figsize_y=10,suptitle='Zeros images')\n",
    "plotMultipleImages(1, 10, zeros_contour_im, zeros_names, cmap=['gray']*10, figsize_x=20, figsize_y=10, suptitle='Contours of Zeros images')\n",
    "plotMultipleImages(1, 10, ones_im, ones_names, cmap=['gray']*10, figsize_x=20, figsize_y=10,suptitle='Ones images')\n",
    "plotMultipleImages(1, 10, ones_contour_im, ones_names, cmap=['gray']*10, figsize_x=20, figsize_y=10, suptitle='Contours of Ones images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Implementation of Fourier descriptors\n",
    "\n",
    "Fourier descriptors are a way of encoding the shape of a two-dimensional object by taking the Fourier transform of the boundary, where every  point on the boundary is mapped to a complex number. Let $(x_n, y_n)$ be the coordinates of the $n^{th}$ pixel on the contour of a given 2D shape, a complex number can be formed as: $C_n = x_n + j*y_n$. Now the Fourier Descriptors are calculated by combining complex array Fourier transform coefficients $C_0,C_1,C_2,......,C_{N-1}$. Thus, the following steps are followed:\n",
    "- We firstly represent the `zeros_contour` and `ones_contour` obtained in previous part as an array of such complex numbers which corresponds to the pixels of the object if the image is placed in the complex plane.\n",
    "- Then the pre-existing function `fft` in numpy is used to compute the Fourier descriptors $(F_0, F_1,...,F_{N-1})$. Users can select the first N descriptors which contain the majority of the shape information of the object as the results. \n",
    "- Because the first descriptor $F_0$ (\"DC-component\") of Fourier transform gives the average power of whole signal and is quite sensitive to the translation, we decided to truncate it to ensure location-invariance and select Fourier descriptors only from $F_1, F_2,...,F_{N-1}$.\n",
    "- The fourier descriptors are complex here, thus we take their amplitudes as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index of selected fourier descriptors: start, start+1, ..., start+N-1\n",
    "def get_Fourier_descriptors(real_contour, start=1, N=2, scale=None):\n",
    "    complex_contour = np.zeros(real_contour.shape[0], dtype=complex)\n",
    "    complex_contour.real = real_contour[:,0]\n",
    "    complex_contour.imag = real_contour[:,1]\n",
    "    \n",
    "    descriptors = np.fft.fft(complex_contour)\n",
    "    if scale:\n",
    "        features = np.abs(descriptors[start:start+N])/np.abs(descriptors[1])\n",
    "    else:\n",
    "        features = np.abs(descriptors[start:start+N])\n",
    "        \n",
    "    return features\n",
    "\n",
    "def get_features(zeros_contour, ones_contour, start=1, N=2, scale=None):\n",
    "    \n",
    "    zeros_features = []\n",
    "    ones_features = []\n",
    "    \n",
    "    for zeros, ones in zip(zeros_contour, ones_contour):\n",
    "        features = get_Fourier_descriptors(zeros, start, N, scale)\n",
    "        zeros_features.append(features)\n",
    "        features = get_Fourier_descriptors(ones, start, N, scale)\n",
    "        ones_features.append(features)\n",
    "        \n",
    "    return np.array(zeros_features), np.array(ones_features)\n",
    "\n",
    "def plot_features(zeros_features, ones_features, annote=None, title=None, plt_ax=None):\n",
    "    if not plt_ax:\n",
    "        plot_method= plt\n",
    "        plt.xlabel('Amplitude of descriptor 1')\n",
    "        plt.ylabel('Amplitude of descriptor 2')\n",
    "    else:\n",
    "        plot_method = plt_ax\n",
    "        plot_method.set_xlabel('Amplitude of descriptor 1')\n",
    "        plot_method.set_ylabel('Amplitude of descriptor 2')\n",
    "    \n",
    "    plot_method.scatter(zeros_features[:,0], zeros_features[:,1], label='digit 0')\n",
    "    plot_method.scatter(ones_features[:,0], ones_features[:,1],label='digit 1')\n",
    "    if annote:\n",
    "        annote_text = [str(i) for i in range(10)]\n",
    "        for text, zeros, ones in zip(annote_text, zeros_features, ones_features):\n",
    "            plot_method.annotate(text, (zeros[0],zeros[1]), textcoords=\"offset points\",\n",
    "                         xytext=(0,10),\n",
    "                         ha='center')\n",
    "            plot_method.annotate(text, (ones[0],ones[1]), textcoords=\"offset points\",\n",
    "                         xytext=(0,10), \n",
    "                         ha='center')\n",
    "    if title:\n",
    "        if not plt_ax:\n",
    "            plt.title(title)\n",
    "        else:\n",
    "            plot_method.set_title(title)\n",
    "            \n",
    "    plot_method.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take features\n",
    "zeros_features, ones_features = get_features(zeros_contour, ones_contour)\n",
    "plot_features(zeros_features, ones_features, annote=True, title='Feature space of digit clusters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments**\n",
    "\n",
    "From the figure above, both digit clusters are well classified by using only two features of Fourier descriptors. It is possible to seperate these two clusters by using a simple linear classifier due to their high inter-variance. Additionally, the Fourier descriptors can capture the intra-variance for each cluster well. From raw images, we can see that most digit-1 objects (except for 1_5.png and 1_9.png) have similar contours, which means that the digit-1 cluster has a small intra-variance and thus it gives a compact form in feature space. For digit-0 cluster, due to the inconsistent written formats of digit-0 objects, it has a high intra-variance and thus it gives a sparse form in feature space, for example, slender 0s (i.e., 0_4.png and 0_9.png) give much lower energy in Fourier descriptors than those fat 0s (i.e., 0_5.png and 0_7.png), and 0_8.png becomes a outlier in feature space because it has much more contours than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 Properties of Fourier descriptor\n",
    "In this section, rotation, translation and scaling are applied on raw images to check if Fourier descriptor is robust to image transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.3.1 Rotation invariance\n",
    "By Image rotation, the image is rotated about its center by specified number of degrees $(\\theta)$, which can be defined by constructing a matrix in the form: $\\begin{bmatrix} \\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta \\end{bmatrix}$. Idealized rotation for the angle $(\\theta)$ can be expressed as multiplication of the every element in the Fourer descriptors array with $e^{-\\theta{i}}$ . The discrete Fourier transform of such an array can be given as: $e^{-\\theta{i}}F_1, e^{-\\theta{i}}F_2,...,e^{-\\theta{i}}F_{N-1}$. Thus, for attaining the rotational invariance it is enough to take the absolute value of each descriptor, because $|e^{-\\theta{i}}| = 1$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(raw_im, degree = 45):\n",
    "    '''\n",
    "        To rotate image with certain degrees. \n",
    "        Degree is positive for anti-clockwise and negative for clockwise.\n",
    "        \n",
    "        Input: grayscale image, rotation degrees. \n",
    "        Output: rotated grayscale image. \n",
    "    '''\n",
    "    # get the dimensions of the image\n",
    "    (height, width) = raw_im.shape\n",
    "    # calculate the center of the image\n",
    "    center = (width // 2, height // 2)\n",
    "    # get a rotation mask\n",
    "    mask = cv.getRotationMatrix2D(center, degree, 1.0)\n",
    "    # rotate the image\n",
    "    rotated_im = cv.warpAffine(src=raw_im, M=mask, dsize=(width,height))\n",
    "    \n",
    "    return rotated_im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the rotate_image function on images\n",
    "zeros_rotate_im = np.zeros(zeros_im.shape).astype(np.uint8)\n",
    "ones_rotate_im = np.zeros(ones_im.shape).astype(np.uint8)\n",
    "degrees = [-20, 40, 100]\n",
    "fig, axes = plt.subplots(2, 2, sharex=True, sharey=True, figsize=(15,10))\n",
    "ax = axes.ravel()\n",
    "zeros_features, ones_features = get_features(zeros_contour, ones_contour)\n",
    "plot_features(zeros_features, ones_features, annote=True, title='Original feature space of digit clusters', plt_ax=ax[0])\n",
    "for i, degree in enumerate(degrees):\n",
    "    for ind, zeros, ones in zip(range(numberOf_im), zeros_im, ones_im):\n",
    "        zeros_rotate_im[ind] = rotate_image(zeros, degree)\n",
    "        ones_rotate_im[ind] = rotate_image(ones, degree)\n",
    "    zeros_rotate_contour, ones_rotate_contour, _ , _ = collect_contours_forAll(numberOf_im, zeros_rotate_im, ones_rotate_im)\n",
    "    zeros_rotate_features, ones_rotate_features = get_features(zeros_rotate_contour, ones_rotate_contour)\n",
    "    plot_features(zeros_rotate_features, ones_rotate_features, annote=True, title='Feature space of digit clusters with {0} degrees rotation'.format(degree), plt_ax=ax[i+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments**\n",
    "\n",
    "After applying the rotation, it is obvious that the two digit clusters are still separable, although there are some slight differences than before. This is to be expected, because we only consider the amplitude of the Fourier descriptors and take the phase out. For those slight differences, we think they are caused by the numerical errors in the calculation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.3.2 Translation invariance\n",
    "Translation refers to the rectilinear shift of an object, i.e., an image from one location to another. If we know the amount of shift in horizontal and the vertical direction, say $(t_x, t_y)$ then we make a transformation matrix e.g. $\\begin{bmatrix} 1 & 0 & t_x \\\\ 0 & 1 & t_y \\end{bmatrix}$. According to the theory [1], the translation affects only the value of discrete Fourier transform’s first element, and the translation invariance can be acquired just by truncating the first element $F_0$. Therefore, in this case we use $F_1$  and $F_2$ to show the scaling invariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_image(raw_im, tx, ty):\n",
    "    '''\n",
    "        To translate image with distances tx, ty. \n",
    "        \n",
    "        Input: grayscale image, translation distance. \n",
    "        Output: translated grayscale image. \n",
    "    '''\n",
    "    # get the dimensions of the image\n",
    "    (height, width) = raw_im.shape\n",
    "    # get a translation mask\n",
    "    mask = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "    # translate the image\n",
    "    translate_im = cv.warpAffine(src=raw_im, M=mask, dsize=(width,height))\n",
    "    \n",
    "    return translate_im.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test image\n",
    "ind = 8\n",
    "test_im = zeros_im[ind]\n",
    "translate_dist = [2, 3]\n",
    "test_translate_im = translate_image(test_im, translate_dist[0], translate_dist[1])\n",
    "images = [test_im, test_translate_im]\n",
    "title = ['ori', 'tra']\n",
    "plotMultipleImages(1, 2, images, title, cmap=['gray']*2, figsize_x=10, figsize_y=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use conservative translation distances because a significant translation might cause parts of image objects to be cropped/hidden (i.e. out of scene) which will definitely change the Fourier descriptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the translate_image function on images\n",
    "zeros_translate_im = np.zeros(zeros_im.shape).astype(np.uint8)\n",
    "ones_translate_im = np.zeros(ones_im.shape).astype(np.uint8)\n",
    "translate_dists = [[2, 3], [-2, -3], [-4, 4]]\n",
    "fig, axes = plt.subplots(2, 2, sharex=True, sharey=True, figsize=(15,8))\n",
    "ax = axes.ravel()\n",
    "zeros_features, ones_features = get_features(zeros_contour, ones_contour)\n",
    "plot_features(zeros_features, ones_features, annote=True, title='Original feature space of digit clusters', plt_ax=ax[0])\n",
    "for i, translate_dist in enumerate(translate_dists):\n",
    "    for ind, zeros, ones in zip(range(numberOf_im), zeros_im, ones_im):\n",
    "        zeros_translate_im[ind] = translate_image(zeros, translate_dist[0], translate_dist[1])\n",
    "        ones_translate_im[ind] = translate_image(ones, translate_dist[0], translate_dist[1])\n",
    "    zeros_translate_contour, ones_translate_contour, _ , _ = collect_contours_forAll(numberOf_im, zeros_translate_im, ones_translate_im)\n",
    "    zeros_translate_features, ones_translate_features = get_features(zeros_translate_contour, ones_translate_contour)\n",
    "    plot_features(zeros_translate_features, ones_translate_features, annote=True, title='Feature space of digit clusters with tx={0}, ty={0} translation distance'.format(translate_dist[0], translate_dist[1]), plt_ax=ax[i+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments**\n",
    "\n",
    "We can see that the cluster patterns with translation are very close to the pattern we obained from original image, showing that the Fourier descriptors are quite robust to translation transformation. These results are quite reasonable because we didn't include the first element $F_0$ to describe features of digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.3.3 Scaling invariance\n",
    "Rescaling an image means changing the dimensions of it, be it width alone, height alone or changing both of them. Here we use `rescale` function from skimage library to resize an image by a given scaling factor. Idealized scaling can be expressed as a multiplication of each element in the array with the real constant $a$. According to the theory [1], scaling transformation can cause scaled Fourier descriptors, which are  $aF_1, aF_2,...,aF_{N-1}$. Thus, to achieve scaling invariance, we can rescale each element by the absolute value of one selected element from the descriptors. Here we select $F_1$ as the rescale factor, and each descriptor is divided by $|F_1|$. As $F_1$ is used to rescale, it cannot be used to desribe the featues of digits anymore. Therefore, in this case we use $F_2$ and $F_3$ to show the scaling invariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test scaling invariance\n",
    "scale_factors = [1, 0.5, 2, 4]\n",
    "threshes = [5, 4, 10, 20]\n",
    "fig, axes = plt.subplots(2, 2, sharex=False, sharey=True, figsize=(15,10))\n",
    "ax = axes.ravel()\n",
    "zeros_scale_list = []\n",
    "ones_scale_list = []\n",
    "for i, scale_factor in enumerate(scale_factors):\n",
    "    scale_shape = (10, int(28*scale_factor), int(28*scale_factor))\n",
    "    zeros_scale_im = np.zeros(scale_shape).astype(np.uint8)\n",
    "    ones_scale_im = np.zeros(scale_shape).astype(np.uint8)\n",
    "    for ind, zeros, ones in zip(range(numberOf_im), zeros_im, ones_im):\n",
    "        zeros_scale_im[ind] = rescale(zeros, scale_factor, preserve_range=True, anti_aliasing=True)\n",
    "        ones_scale_im[ind] = rescale(ones, scale_factor, preserve_range=True, anti_aliasing=(scale_factor<1))\n",
    "    zeros_scale_list.append(zeros_scale_im)\n",
    "    ones_scale_list.append(ones_scale_im)\n",
    "    zeros_scale_contour, ones_scale_contour, _, _ = collect_contours_forAll(numberOf_im, zeros_scale_im, ones_scale_im, thresh=threshes[i])\n",
    "    zeros_scale_features, ones_scale_features = get_features(zeros_scale_contour, ones_scale_contour, start=2, N=2, scale=True)\n",
    "    plot_features(zeros_scale_features, ones_scale_features, annote=True, title='Feature space of digit clusters with scale factor = {0}'.format(scale_factor), plt_ax=ax[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When images are scaled up, the resultant feature spaces are quite close to the one we obtained from original image, which demonstrate the Fourier descriptors are robust to scaling invariance. However, when the image is scaled down (here the scale factor = 0.5), we can see that the cluster of 0 digits is towarding to the cluster of 1 digits, and some 0 digits are even mixed with 1 digits, e.g., 0_0.png,  0_7.png, 0_8.png. In order to address this issue, we check the contours of downsaled images, as shwon below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_imags_and_contours(imgs, imgs_names, title):\n",
    "    num_digits = len(imgs)\n",
    "    fig, axes = plt.subplots(num_digits, len(zeros_im), figsize=(15, 4))\n",
    "    for im_axes, img, names in zip(axes, imgs, imgs_names):\n",
    "        fig.suptitle(t=title, y=0.9)\n",
    "        for ax, im, nm in zip(im_axes, img, names):\n",
    "            _, _, _, contours, _, _ = pre_processing(im)\n",
    "            ax.imshow(im, cmap='gray')\n",
    "            for cont in sorted(contours, key=lambda x: x.shape[0], reverse=True):\n",
    "                ax.plot(cont[:,1], cont[:,0], linewidth=3)\n",
    "            ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plot_imags_and_contours([zeros_scale_list[0], zeros_scale_list[1]], [zeros_names, zeros_names], title='Original 0s (above) and Downscaled 0s (bottom)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the some contours obtained from downscaled images are quite different than the original ones, especially for 0_0.png, 0_6.png, 0_7.png and 0_8.png. This is due to the downscale that causes the digit shapes thiner. Thiner edge is weaker than before so that it is segmented into multiple parts, it is quite hard to obain the similar contours as the original ones by using the same pre-preocessing methods we developed before. Thus, the downscaling invariance might not be guaranteed if we decrease the scaling factor futher. In order to keep the scaling invariance, we think the pre-preocessing methods should be redesigned to make sure the obtained contours of digits for each scaling case are similar. Of course, this will come at the cost of reducing the generality of our algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "To conclude, we demonstrate how the Fourier descriptors can dinstingush the digit-0 and digit-1 by using only 2 features. Moreever, the transformation invariances of Fourier descriptors (e.g., translation, scaling, and rotation) are verified. However, we believe that the good classification results are not only due to the power of the Fourier describtors, but also to the very different Intrinsic shapes of the two numbers. Classifying digits with similar shapes (like digits 2 and 3 proposed in Part 2) may not achieve the same performance as here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4 Discussion on using Fourier descriptors (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Additional method (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different features are extracted for digits separation, which are list as follows\n",
    "\n",
    "1. area of the digit $S$\n",
    "2. perimeter of the digit $P$\n",
    "3. the filled area of digits after computing contours $S_f$\n",
    "4. ratio of filled area to perimeter $S_f/P$\n",
    "5. distribution historgram of the pixels from the center of mass\n",
    "    1. calculate the center of mass (CoM) of the digits.\n",
    "    2. calculate the rotated angle and main axis by finding minimal rotated enclosing rectangle or ellipse with `cv2.minAreaRect` or `cv2.fitEllipse`.\n",
    "    3. divide the 360 degrees into $x$ bins ($x$ is set as 12, i.e., 30 degrees is the bin size) and put the digit pixel into different bins by calculating angle between main axis and CoM to pixel.\n",
    "    4. calculate the standard deviation of normalized histogram (as shown in **Fig 1.3.2** and **1.3.3**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import find_contours\n",
    "from skimage import img_as_float, img_as_bool\n",
    "# from scipy import ndimage as ndi\n",
    "# ndi.center_of_mass\n",
    "# ndi.binary_fill_holes\n",
    "# find_contours: https://scikit-image.org/docs/stable/api/skimage.measure.html#skimage.measure.find_contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your implementation and discussion\n",
    "def compute_area(binary_img, background=0):\n",
    "    bool_img = img_as_bool(binary_img)\n",
    "    return np.sum(bool_img != background)\n",
    "\n",
    "def compute_perimeter(binary_img, compute_all = True):\n",
    "    bool_img = img_as_bool(binary_img) # use bool or not\n",
    "    contours = find_contours(bool_img, 0.8)\n",
    "    # todo: discuss feature\n",
    "    if compute_all:\n",
    "        contour_len = np.sum([len(cnt) for cnt in contours])\n",
    "    else:\n",
    "        # Select the largest contiguous contour\n",
    "        contour = sorted(contours, key=lambda x: len(x))[-1]\n",
    "        contour_len = len(contour)\n",
    "    return contour_len\n",
    "\n",
    "def compute_filled_area(binary_img, background=0):\n",
    "    bool_img = img_as_bool(copy.deepcopy(binary_img))\n",
    "    contours = find_contours(bool_img, 0.8)\n",
    "    # print(\"Detected contours: \",len(contours))\n",
    "    contour = sorted(contours, key=lambda x: len(x))[-1]\n",
    "    filled_img = np.zeros_like(bool_img, dtype='bool')\n",
    "    filled_img[np.round(contour[:, 0]).astype('int'), np.round(contour[:, 1]).astype('int')] = 1\n",
    "    filled_img = ndi.binary_fill_holes(filled_img)\n",
    "    origin_area = compute_area(binary_img, background=0)\n",
    "    filled_area = np.sum(filled_img != background)\n",
    "    if filled_area < origin_area:\n",
    "        filled_area = origin_area\n",
    "    return filled_area\n",
    "\n",
    "# ndi.center_of_mass(bool_test_im)\n",
    "def compute_com(binary_img, background=0):\n",
    "    bool_img = img_as_bool(binary_img)\n",
    "    return np.round(np.mean(np.argwhere(bool_img==1),axis=0)).astype('int')\n",
    "\n",
    "def compute_rotate_angles(binary_img, use_ellipse=True):\n",
    "    bool_img = img_as_bool(binary_img)\n",
    "    img_array = Image.fromarray(np.uint8(bool_img*255))\n",
    "    cv_image = np.array(img_array) \n",
    "    _, thresh = cv2.threshold(cv_image, 127, 255, 0)\n",
    "    contours, _ = cv2.findContours(thresh, 1, 2)\n",
    "    cnt = contours[0]\n",
    "    cnt = cv2.convexHull(cnt)\n",
    "    # print(\"Rectangle axis angle:\", rect[2])\n",
    "    if use_ellipse and cnt.shape[0]>=5:\n",
    "        ellipse = cv2.fitEllipse(cnt)\n",
    "        angle_rot = ellipse[-1]\n",
    "        if angle_rot < 90:\n",
    "            angle_rot = angle_rot\n",
    "        else:\n",
    "            angle_rot = angle_rot - 180\n",
    "        # ellipse_im = cv2.ellipse(binary_im, ellipse,(0,255,0),2)\n",
    "        # print(\"Ellipse axis angle from vertical:\", angle_trans)\n",
    "    else:\n",
    "        rect = cv2.minAreaRect(cnt)\n",
    "        # box = cv2.boxPoints(rect)\n",
    "        # box = np.int0(box)\n",
    "        # print(\"Not stable -> Not implemented!\")\n",
    "        angle_rot = rect[-1]\n",
    "        p = np.array(rect[1])\n",
    "        if p[0] < p[1]:\n",
    "            act_angle = angle_rot + 180\n",
    "        else:\n",
    "            act_angle = angle_rot + 90\n",
    "        if act_angle < 90:\n",
    "            angle_rot = 90 + angle_rot\n",
    "        else:\n",
    "            angle_rot = act_angle - 180\n",
    "    return angle_rot\n",
    "\n",
    "def img_cor_trans(image_cor, x_max=28):\n",
    "    return [image_cor[1], x_max-image_cor[0]-1]\n",
    "\n",
    "# bins = 18\n",
    "# print(np.linspace(0, 360, bins+1).astype('int'))\n",
    "# bin_size = 20\n",
    "# print(np.arange(0, 360+bin_size, bin_size))\n",
    "def compute_dist_hist(binary_img, bin_num=12, use_ellipse=True):\n",
    "    # calculate rotated angles\n",
    "    angle_trans = compute_rotate_angles(binary_img, use_ellipse)\n",
    "    \n",
    "    ## calculate histogram \n",
    "    # make as bool\n",
    "    bool_img = img_as_bool(binary_img)\n",
    "    # compute center of mass\n",
    "    com = compute_com(bool_img)\n",
    "    # print('Center of mass:', com)\n",
    "    trans_com = img_cor_trans(com)\n",
    "    # print(trans_com)\n",
    "    pixels = np.argwhere(bool_img==1)\n",
    "    # calculate degrees for each pixels\n",
    "    degrees = []\n",
    "    for pixel in pixels:\n",
    "        trans_pixel = img_cor_trans(pixel)\n",
    "        y = trans_pixel[1] - trans_com[1]\n",
    "        x = trans_pixel[0] - trans_com[0]\n",
    "        ang = np.arctan2(y, x) * 180 / np.pi\n",
    "        corr_ang = angle_trans + ang\n",
    "        if corr_ang < 0:\n",
    "            corr_ang += 360\n",
    "        degrees.append(corr_ang)\n",
    "    hist, bin_edges = np.histogram(degrees, bins=np.linspace(0, 360, bin_num+1).astype('int'))\n",
    "    return hist, bin_edges\n",
    "\n",
    "# ref: https://stackoverflow.com/a/52976715\n",
    "def viz_deg_dist(hist, bin_edges, ax=None, new_fig=False):\n",
    "    # degrees = np.random.randint(0, 360, size=200)\n",
    "    # radians = np.deg2rad(degrees)\n",
    "    bin_size = 360 / len(hist)\n",
    "    centers = np.deg2rad(np.ediff1d(bin_edges)//2 + bin_edges[:-1])\n",
    "\n",
    "    if new_fig:\n",
    "        fig = plt.figure(figsize=(10,8))\n",
    "        ax = fig.add_subplot(111, projection='polar')\n",
    "    ax.bar(centers, hist, width=np.deg2rad(bin_size), bottom=0.0, color='.8', edgecolor='k')\n",
    "    ax.set_theta_zero_location(\"N\")\n",
    "    ax.set_theta_direction(-1)\n",
    "    if new_fig:\n",
    "        plt.show()\n",
    "    \n",
    "def compute_hist_std(hist):\n",
    "    hist_nor = [ele/sum(hist) for ele in hist]\n",
    "    hist_std = np.std(hist_nor)\n",
    "    # TODO: use top2 bin dominance ...\n",
    "    return hist_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_feats(imgs):\n",
    "    feat = {\n",
    "        'area': [],\n",
    "        'filled_area': [],\n",
    "        'perimeter': [],\n",
    "        'filled2peri': [],\n",
    "        'hist_std': [],\n",
    "                 }\n",
    "\n",
    "    for idx, img in enumerate(imgs):\n",
    "        im_area = compute_area(img)\n",
    "        im_filled_area = compute_filled_area(img)\n",
    "        im_perimeter = compute_perimeter(img)\n",
    "        hist, bin_edges = compute_dist_hist(img, bin_num=12)\n",
    "        im_hist_std = compute_hist_std(hist)\n",
    "        feat['area'].append(im_area)\n",
    "        feat['filled_area'].append(im_filled_area)\n",
    "        feat['perimeter'].append(im_perimeter)\n",
    "        feat['filled2peri'].append(im_filled_area/im_perimeter)\n",
    "        feat['hist_std'].append(im_hist_std)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.3 Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fig 1.3.1 Comparison of original image, and its binary and filled format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "# 1 - test_im\n",
    "axes[0].imshow(test_im, cmap='gray')\n",
    "\n",
    "# 2 - bool_test_im\n",
    "bool_test_im = img_as_bool(test_im)\n",
    "axes[1].imshow(bool_test_im, cmap='gray')\n",
    "\n",
    "# 3 - filled_test_im\n",
    "contour = find_contours(bool_test_im, 0.8)\n",
    "filled_test_im = np.zeros_like(bool_test_im, dtype='bool')\n",
    "# Create a contour image by using the contour coordinates rounded to their nearest integer value\n",
    "filled_test_im[np.round(contour[0][:, 0]).astype('int'), np.round(contour[0][:, 1]).astype('int')] = 1\n",
    "filled_test_im = ndi.binary_fill_holes(filled_test_im)\n",
    "axes[2].imshow(filled_test_im, cmap='gray')\n",
    "\n",
    "plt.suptitle(\n",
    "    \"Fig 1.3.1 Comparison of original image, and its binary and filled format\",\n",
    "    fontweight='bold', size=14\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Area:', compute_area(test_im))\n",
    "print('Filled area:', compute_filled_area(test_im))\n",
    "print('Perimeter:', compute_perimeter(test_im))\n",
    "print('Center of mass:', compute_com(test_im))\n",
    "print('Center of mass:', compute_com(test_translate_im))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fig 1.3.2 Digit 0 example and its correspoding pixel distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im0 = zeros_im[5]\n",
    "print('Area:', compute_area(im0))\n",
    "print('Filled area:', compute_filled_area(im0))\n",
    "print('Perimeter:', compute_perimeter(im0))\n",
    "print('Center of mass:', compute_com(im0))\n",
    "\n",
    "bool_im0 = img_as_bool(im0)\n",
    "im0_array = Image.fromarray(np.uint8(bool_im0*255))\n",
    "cv_image = np.array(im0_array) \n",
    "\n",
    "## calculate angles to obtain hist\n",
    "angle_ell = compute_rotate_angles(im0, use_ellipse=True)\n",
    "print(\"Ellipse axis angle from vertical:\", angle_ell)\n",
    "hist, bin_edges = compute_dist_hist(im0)\n",
    "print('Std of Histogram:', compute_hist_std(hist))\n",
    "\n",
    "## viz\n",
    "fig = plt.figure(figsize=(12, 6), constrained_layout=True)\n",
    "spec = fig.add_gridspec(2, 3)\n",
    "\n",
    "ax00 = fig.add_subplot(spec[0, 0])\n",
    "ax00.imshow(im0)\n",
    "ax00.set_title('raw')\n",
    "ax00.set_xlabel('y')\n",
    "ax00.set_ylabel('x')\n",
    "\n",
    "ax01 = fig.add_subplot(spec[1, 0])\n",
    "ax01.imshow(bool_im0)\n",
    "ax01.set_title('bool_im0')\n",
    "ax01.set_xlabel('y')\n",
    "ax01.set_ylabel('x')\n",
    "\n",
    "ax1 = fig.add_subplot(spec[:, 1:], projection='polar')\n",
    "viz_deg_dist(hist, bin_edges, ax=ax1)\n",
    "\n",
    "plt.suptitle(\n",
    "    \"Fig 1.3.2 Digit 0 example and its correspoding pixel distribution\",\n",
    "    fontweight='bold', size=14\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fig 1.3.3 Digit 1 example and its correspoding pixel distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref\n",
    "# https://opencv24-python-tutorials.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_contours/py_contour_features/py_contour_features.html\n",
    "# https://github.com/rtharungowda/hcg/blob/2cc3125e120d3279bfe8daf89e16f28d38ac4767/segmentation.py\n",
    "im1 = ones_im[0]\n",
    "\n",
    "print('Area:', compute_area(im1))\n",
    "print('Filled area:', compute_filled_area(im1))\n",
    "print('Perimeter:', compute_perimeter(im1))\n",
    "print('Center of mass:', compute_com(im1))\n",
    "\n",
    "bool_im1 = img_as_bool(im1)\n",
    "im1_array = Image.fromarray(np.uint8(bool_im1*255))\n",
    "cv_image = np.array(im1_array) \n",
    "\n",
    "## calculate angles to obtain hist\n",
    "angle_ell = compute_rotate_angles(im1, use_ellipse=True)\n",
    "print(\"Ellipse axis angle from vertical:\", angle_ell)\n",
    "hist, bin_edges = compute_dist_hist(im1)\n",
    "print('Std of Histogram:', compute_hist_std(hist))\n",
    "\n",
    "## viz\n",
    "fig = plt.figure(figsize=(12, 6), constrained_layout=True)\n",
    "spec = fig.add_gridspec(2, 3)\n",
    "\n",
    "ax00 = fig.add_subplot(spec[0, 0])\n",
    "ax00.imshow(im1)\n",
    "ax00.set_title('raw')\n",
    "ax00.set_xlabel('y')\n",
    "ax00.set_ylabel('x')\n",
    "\n",
    "ax01 = fig.add_subplot(spec[1, 0])\n",
    "ax01.imshow(cv_image)\n",
    "ax01.set_title('cv_image')\n",
    "ax01.set_xlabel('y')\n",
    "ax01.set_ylabel('x')\n",
    "\n",
    "ax1 = fig.add_subplot(spec[:, 1:], projection='polar')\n",
    "viz_deg_dist(hist, bin_edges, ax=ax1)\n",
    "\n",
    "plt.suptitle(\n",
    "    \"Fig 1.3.3 Digit 1 example and its correspoding pixel distribution\",\n",
    "    fontweight='bold', size=14\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.4 Extract features to cluster digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3.4.1 Performance on original images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat0_ori = compute_feats(zeros_im)\n",
    "feat1_ori = compute_feats(ones_im)\n",
    "feat0_ori "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fig 1.3.4 Feature space of digit clusters by using digit area and perimeter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_feats = np.array([feat0_ori['area'], feat0_ori['perimeter']]).T\n",
    "ones_feats = np.array([feat1_ori['area'], feat1_ori['perimeter']]).T\n",
    "plot_features(zeros_feats, \n",
    "              ones_feats, \n",
    "              annote=True, \n",
    "              loc='upper right',\n",
    "              title='Fig 1.3.4 Feature space of digit clusters by using digit area and perimeter',\n",
    "              xlabel='Area',\n",
    "              ylabel='Perimeter'\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fig 1.3.5 Feature space of digit clusters by using composed features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zeros_feats = np.array([feat0_ori['filled2peri'], feat0_ori['hist_std']]).T\n",
    "ones_feats = np.array([feat1_ori['filled2peri'], feat1_ori['hist_std']]).T\n",
    "plot_features(zeros_feats, \n",
    "              ones_feats, \n",
    "              annote=True, \n",
    "              loc='upper right',\n",
    "              title='Fig 1.3.5 Feature space of digit clusters by using composed features',\n",
    "              xlabel='Filled Area/Perimeter',\n",
    "              ylabel='Std of Pixel Distribution Histogram w.r.t. CoM'\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3.4.2 Invariant performance to different transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_im, zeros_names = load(data_part1, digit='0')\n",
    "ones_im, ones_names = load(data_part1, digit='1')\n",
    "\n",
    "zeros_rotate_im = np.zeros(zeros_im.shape).astype(np.uint8)\n",
    "ones_rotate_im = np.zeros(ones_im.shape).astype(np.uint8)\n",
    "degree = 60\n",
    "\n",
    "zeros_translate_im = np.zeros(zeros_im.shape).astype(np.uint8)\n",
    "ones_translate_im = np.zeros(ones_im.shape).astype(np.uint8)\n",
    "translate_dist = [2, -3]\n",
    "\n",
    "# TODO: possible ValueError: could not broadcast input array from shape (56,56) into shape (14,14)\n",
    "scale_factor = 0.5\n",
    "scale_shape = (10, int(28*scale_factor), int(28*scale_factor))\n",
    "zeros_scale_im = np.zeros(scale_shape).astype(np.uint8)\n",
    "ones_scale_im = np.zeros(scale_shape).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, zeros, ones in zip(range(numberOf_im), zeros_im, ones_im):\n",
    "    zero_process = copy.deepcopy(zeros)\n",
    "    one_process = copy.deepcopy(ones)\n",
    "    \n",
    "    zeros_rotate_im[ind] = rotate_image(zero_process, degree)\n",
    "    ones_rotate_im[ind] = rotate_image(one_process, degree)\n",
    "    \n",
    "    zeros_translate_im[ind] = translate_image(zero_process, translate_dist[0], translate_dist[1])\n",
    "    ones_translate_im[ind] = translate_image(one_process, translate_dist[0], translate_dist[1])\n",
    "    \n",
    "    zeros_scale_im[ind] = rescale(zero_process, scale_factor, preserve_range=True, anti_aliasing=False)\n",
    "    ones_scale_im[ind] = rescale(one_process, scale_factor, preserve_range=True, anti_aliasing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fig 1.3.6 Example of different transformation on the digits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_invar, axes_invar = plt.subplots(2, 2, sharex=False, sharey=False, figsize=(7,6))\n",
    "ax_invar = axes_invar.ravel()\n",
    "\n",
    "ax_invar[0].imshow(ones_im[0])\n",
    "ax_invar[0].set_title(\"Original\")\n",
    "ax_invar[0].axis('off')\n",
    "ax_invar[1].imshow(ones_rotate_im[0])\n",
    "ax_invar[1].set_title(\"Rotate 60 degrees\")\n",
    "ax_invar[1].axis('off')\n",
    "ax_invar[2].imshow(ones_translate_im[0])\n",
    "ax_invar[2].set_title(\"Translate [2, -3]\")\n",
    "ax_invar[2].axis('off')\n",
    "ax_invar[3].imshow(ones_scale_im[0])\n",
    "ax_invar[3].set_title(\"Scale x 0.5\")\n",
    "ax_invar[3].axis('off')\n",
    "\n",
    "plt.suptitle(\n",
    "    \"Fig 1.3.6 Example of different transformation on the digits\",\n",
    "    fontweight='bold', size=14\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fig 1.3.7 Clustering results under different transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_append = [\n",
    "    '',\n",
    "    ' (Rotate 60 degrees)',\n",
    "    ' (Translate [2, -3])', \n",
    "    ' (Scale x 0.5)', \n",
    "]\n",
    "\n",
    "fig_new, axes_new = plt.subplots(2, 2, sharex=False, sharey=False, figsize=(15,10))\n",
    "ax_new_ = axes_new.ravel()\n",
    "\n",
    "for idx, (zeros_im, ones_im) in enumerate([\n",
    "    (zeros_im, ones_im),\n",
    "    (zeros_rotate_im, ones_rotate_im),\n",
    "    (zeros_translate_im, ones_translate_im),\n",
    "    (zeros_scale_im, ones_scale_im),\n",
    "]):\n",
    "    if idx == 0:\n",
    "        feat0 = feat0_ori\n",
    "        feat1 = feat1_ori\n",
    "    else:\n",
    "        feat0 = compute_feats(zeros_im)\n",
    "        feat1 = compute_feats(ones_im)\n",
    "    zeros_feats = np.array([feat0['filled2peri'], feat0['hist_std']]).T\n",
    "    ones_feats = np.array([feat1['filled2peri'], feat1['hist_std']]).T\n",
    "    plot_features(zeros_feats, \n",
    "                  ones_feats, \n",
    "                  annote=True, \n",
    "                  title='Feature space of digit clusters'+title_append[idx],\n",
    "                  loc='upper right',\n",
    "                  xlabel='Filled Area/Perimeter',\n",
    "                  ylabel='Std of Pixel Distribution Histogram w.r.t. CoM',\n",
    "                  plt_ax = ax_new_[idx],\n",
    "                  xlim=[0.2, 2.4],\n",
    "                  ylim=[0.0, 0.15],\n",
    "                 )\n",
    "plt.suptitle(\n",
    "    \"Fig 1.3.7 Clustering results under different transformation\",\n",
    "    fontweight='bold', size=14\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.5 Discussion on using different methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. As shown in Fig 1.3.4, simple parameter, such as area and perimeter can separate the two classes, but it can be easily influenced by outliers.\n",
    "2. As shown in Fig 1.3.5, Calculating the filled area removed the outlier problem and comparing the filled area with perimeter can improve clusterization. \n",
    "3. Fig 1.3.7 shows composed features such as Filled Area/Perimeter, and standard deviation of pixel distribution are mostly robust to bounded translation and rotation, but only is more standard deviation of pixel distribution against scaling.\n",
    "3. Possible failure cases may happen when translate outside the range, resulting inconsistent pixels compare to original image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2\n",
    "The `lab-02-data/part2` folder contains grey-scale pictures of handwritten \"2\" and \"3\".\n",
    "Extract the same feature (typically 2 Fourier descriptors) as in part 1 also on these images and plot them on the same graph as the features of the \"0\" and \"1\".\n",
    "Is it possible to discriminate all these 4 digits with a 2-dimensional feature vector?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load twos and threes\n",
    "twos_im, twos_names = load(data_part2, digit='2')\n",
    "threes_im, threes_names = load(data_part2, digit='3')\n",
    "\n",
    "# Plot images\n",
    "fig, axes = plt.subplots(2, len(twos_im), figsize=(12, 3))\n",
    "for ax, im, nm in zip(axes[0], twos_im, twos_names):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n",
    "for ax, im, nm in zip(axes[1], threes_im, threes_names):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Fourier descriptors - 4 digits (10 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Denoising\n",
    "\n",
    "As image edges are very susceptible to noise, filtering of the image is required to remove noise in order to avoid detecting false edge information. One effective method of denoising is to perform filtering. The filtering process smoothes out some of the less textured non-edge areas in order to get a more accurate edge. In practical processing, there are many filters to choose from, such as linear filtering, median filter, homomorphic filtering, etc.\n",
    "\n",
    "Considering the features of this task, We choose Gaussian Filter in part 2. The Gaussian filter is a linear filter that **1)** effectively suppresses noise and **2)** smoothes the image. It works similarly to a mean filter in that it takes the mean value of the pixels within the filter window as its output. The coefficients of the window template are different from those of the mean filter, as the coefficients of the mean filter's template are all the same at 1. The coefficients of the Gaussian filter's template decrease as the distance from the centre of the template increases. Therefore, the Gaussian filter is **3)** less blurred than the mean filter.\n",
    "\n",
    "* Morphological operations\n",
    "\n",
    "opening: To remove some white patches caused by residual noise (can be found in 3_6.png)\n",
    "closing: Try to remove internal holes and smooth the border(eg 2_0.png, 2_1.png, 2_5.png)\n",
    "\n",
    "* Thresholding\n",
    "\n",
    "make the images binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot multiple images\n",
    "\n",
    "def plotMultipleImages(nrows, ncols, images, titles, cmap, figsize_x=14, figsize_y=7, suptitle=None):\n",
    "    fig = plt.figure(figsize=(figsize_x,figsize_y))\n",
    "    fig.suptitle(t=suptitle, y=0.63)\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.3)\n",
    "    for i in range(len(titles)):\n",
    "        ax = fig.add_subplot(nrows, ncols, i+1)\n",
    "        if cmap[i]=='rgb':\n",
    "            ax.imshow(images[i])\n",
    "        else:\n",
    "            ax.imshow(images[i], cmap=cmap[i])\n",
    "        ax.set_title(titles[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test image\n",
    "ind = 3\n",
    "test_im = twos_im[ind]\n",
    "test_im_name = twos_names[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the histrogram ditribution\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 3))\n",
    "ax[0].imshow(test_im, cmap='gray')\n",
    "ax[0].set_title(test_im_name)\n",
    "ax[0].axis('off') \n",
    "ax[1].hist(test_im.ravel(), bins=256) \n",
    "ax[1].set_title('256 bins historgram of '+test_im_name)\n",
    "ax[1].set_xlabel('Pixel intensity')\n",
    "ax[1].set_ylabel('Number of pixels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ordered_contour(in_im):\n",
    "    # a list of the coordinates of the contour pixels (float type)  \n",
    "    contours = measure.find_contours(in_im, 5)\n",
    "    ordered_contour = []\n",
    "    contour_im = np.zeros(in_im.shape).astype(np.uint8)\n",
    "    contour_len = []\n",
    "    for contour in contours:\n",
    "        contour_len.append(contour.shape[0])\n",
    "        contour = np.rint(contour).astype(np.uint8)\n",
    "        for x,y in contour:\n",
    "            ordered_contour.append((x,y))\n",
    "            contour_im[x,y] = 255\n",
    "    return np.array(ordered_contour).astype(int), contour_im\n",
    "\n",
    "\n",
    "def pre_processing(in_im, thresh=5):\n",
    "    #Denoising\n",
    "    gaussian_im =  cv.GaussianBlur(in_im, (1,1),0)\n",
    "    # Image binarization\n",
    "    # Otsu's thresholding\n",
    "    _,binary_im = cv.threshold(gaussian_im, 0, 255, cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "    # Morphological opening\n",
    "    # morph_im = skimage.morphology.diameter_opening(median_im,thresh)\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_RECT, (2,2))\n",
    "    # closing\n",
    "    im = cv.morphologyEx(binary_im, cv.MORPH_CLOSE, kernel, iterations=1)\n",
    "    # morph_im = skimage.morphology.diameter_opening(im,thresh)\n",
    "    # get the orderred contours\n",
    "    ordered_contour, contour_im = get_ordered_contour(im)\n",
    "    \n",
    "    return contour_im, ordered_contour\n",
    "\n",
    "def collect_contours_forAll(numberOf_im, zeros_im, ones_im, thresh=5):\n",
    "    # compute the contour coordinates\n",
    "    zeros_contour = []\n",
    "    ones_contour = []\n",
    "    zeros_contour_im = np.zeros(twos_im.shape).astype(np.uint8)\n",
    "    ones_contour_im = np.zeros(threes_im.shape).astype(np.uint8)\n",
    "    for ind, zeros, ones in zip(range(numberOf_im), zeros_im, ones_im):\n",
    "        contour_im, ordered_contour = pre_processing(zeros)\n",
    "        zeros_contour_im[ind] = contour_im\n",
    "        zeros_contour.append(ordered_contour)\n",
    "        contour_im, ordered_contour = pre_processing(ones, thresh)\n",
    "        ones_contour_im[ind] = contour_im\n",
    "        ones_contour.append(ordered_contour)\n",
    "    return zeros_contour, ones_contour, zeros_contour_im, ones_contour_im\n",
    "\n",
    "twos_contour, threes_contour, zeros_contour_im, ones_contour_im = collect_contours_forAll(numberOf_im, twos_im, threes_im)\n",
    "# display the plots\n",
    "plotMultipleImages(1, 10, twos_im, twos_names, cmap=['gray']*10, figsize_x=20, figsize_y=10,suptitle='Twos images')\n",
    "plotMultipleImages(1, 10, zeros_contour_im, twos_names, cmap=['gray']*10, figsize_x=20, figsize_y=10, suptitle='Contours of Twos images')\n",
    "plotMultipleImages(1, 10, threes_im, threes_names, cmap=['gray']*10, figsize_x=20, figsize_y=10,suptitle='Threes images')\n",
    "plotMultipleImages(1, 10, ones_contour_im, threes_names, cmap=['gray']*10, figsize_x=20, figsize_y=10, suptitle='Contours of Threes images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**\n",
    "\n",
    "Generally, the contours of the images are portrayed acceptably, but again some noise was generated during processing, as in 2_0.png the internal holes are not handled very well, the same problem occurs in 2_1png and 2_5.png. We tried to combine morphological opening and closing operations with gaussian denoising, but never got the most desirable results, hence the current state is presented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Implementation of Fourier descriptors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index of selected fourier descriptors: start, start+1, ..., start+N-1\n",
    "def get_Fourier_descriptors(real_contour, start=1, N=2, scale=None):\n",
    "    complex_contour = np.zeros(real_contour.shape[0], dtype=complex)\n",
    "    complex_contour.real = real_contour[:,0]\n",
    "    complex_contour.imag = real_contour[:,1]\n",
    "    \n",
    "    descriptors = np.fft.fft(complex_contour)\n",
    "    \n",
    "    if scale:\n",
    "        features = np.abs(descriptors[start:start+N])/np.abs(descriptors[0])\n",
    "    else:\n",
    "        features = np.abs(descriptors[start:start+N])\n",
    "        \n",
    "    return features\n",
    "\n",
    "def get_features(twos_contour, threes_contour, start=1, N=2, scale=None):\n",
    "    \n",
    "    twos_features = []\n",
    "    threes_features = []\n",
    "    \n",
    "    for twos, threes in zip(twos_contour, threes_contour):\n",
    "        features = get_Fourier_descriptors(twos, start, N, scale)\n",
    "        twos_features.append(features)\n",
    "        features = get_Fourier_descriptors(threes, start, N, scale)\n",
    "        threes_features.append(features)\n",
    "        \n",
    "    return np.array(twos_features), np.array(threes_features)\n",
    "\n",
    "def plot_features(twos_features, threes_features, annote=None, title=None, plt_ax=None,p1=None):\n",
    "    if not plt_ax:\n",
    "        plot_method= plt\n",
    "        plt.xlabel('Amplitude of descriptor 1')\n",
    "        plt.ylabel('Amplitude of descriptor 2')\n",
    "        # 如果需要画在同一张图中，设置p1=True\n",
    "        if p1:\n",
    "            plot_method.scatter(twos_features[:,0], twos_features[:,1], label='digit 0')\n",
    "            plot_method.scatter(threes_features[:,0], threes_features[:,1], label='digit 1')\n",
    "        else:\n",
    "            plot_method.scatter(twos_features[:,0], twos_features[:,1], label='digit 2')\n",
    "            plot_method.scatter(threes_features[:,0], threes_features[:,1], label='digit 3')\n",
    "    else:\n",
    "        plot_method = plt_ax\n",
    "        plot_method.set_xlabel('Amplitude of descriptor 1')\n",
    "        plot_method.set_ylabel('Amplitude of descriptor 2')\n",
    "        plot_method.set_zlabel('Ampltitude of deacriptor 3')\n",
    "        # 如果需要画在同一张图中，设置p1=True\n",
    "        if p1:\n",
    "            plot_method.scatter(twos_features[:,0], twos_features[:,1],twos_features[:,2], label='digit 0',marker=\"o\",s=100)\n",
    "            plot_method.scatter(threes_features[:,0], threes_features[:,1],twos_features[:,2], label='digit 1',marker=\".\",s=100)\n",
    "        else:\n",
    "            plot_method.scatter(twos_features[:,0], twos_features[:,1],twos_features[:,2], label='digit 2',marker=\"v\",s=100)\n",
    "            plot_method.scatter(threes_features[:,0], threes_features[:,1],twos_features[:,2], label='digit 3',marker=\"x\",s=100)\n",
    "\n",
    "    if annote:\n",
    "        annote_text = [str(i) for i in range(10)]\n",
    "        for text, twos, threes in zip(annote_text, twos_features, threes_features):\n",
    "            plot_method.annotate(text, (twos[0],twos[1]), textcoords=\"offset points\",\n",
    "                         xytext=(0,10),\n",
    "                         ha='center')\n",
    "            plot_method.annotate(text, (threes[0],threes[1]), textcoords=\"offset points\",\n",
    "                         xytext=(0,10), \n",
    "                         ha='center')\n",
    "    if title:\n",
    "        if not plt_ax:\n",
    "            plt.title(title)\n",
    "        else:\n",
    "            plot_method.set_title(title)\n",
    "            \n",
    "    plot_method.legend(loc='lower right')\n",
    "\n",
    "# take features of 2, 3\n",
    "# fig = plt.figure(figsize=(6,6))\n",
    "# ax = fig.add_subplot(projection='3d')\n",
    "twos_features, threes_features = get_features(twos_contour, threes_contour, N=2)\n",
    "plot_features(twos_features, threes_features, annote=True, title='Fig2.1 Feature space of digit clusters', plt_ax=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Finally, we extract the same feature (2 Fourier descriptors) as in part 1 also on these images and plot them on the same graph as the features of the \"0\" and \"1\", so we got Fig2.2  \"Feature space of digit clusters 0-1-2-3\" as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "zeros_features, ones_features = get_features(zeros_contour, ones_contour,N=3,start=0)\n",
    "plot_features(zeros_features, ones_features, annote=True, p1='p1',plt_ax=ax)\n",
    "\n",
    "# take features of 2, 3\n",
    "twos_features, threes_features = get_features(twos_contour, threes_contour,N=3,start=0)\n",
    "plot_features(twos_features, threes_features, annote=True, title='Fig2.2 Feature space of digit clusters 0-1-2-3',plt_ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**\n",
    "1. FROM Fig2.1\n",
    "    1. The feature space reveals that the points in the figure can be basically divided into two clusters, one of which is distributed on the upper left side (number 2) and one on the lower right side (number 3).\n",
    "    2. Because of the morphological similarity of some of the handwritten letters, especially 3_3 and 2_4,2_5, which share many of the same shapes, the Fourier descriptor feature distributions of the two have a high degree of similarity, which is not conducive to differentiation but is reasonable.\n",
    "    \n",
    "\n",
    "2. FROM Fig2.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Is it possible to discriminate all these 4 digits with a 2-dimensional feature vector?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "289.396px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
