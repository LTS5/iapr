{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8uJCioevSmGc"
   },
   "source": [
    "# [IAPR][iapr]: Lab 2 â€’  Object description\n",
    "\n",
    "**Group ID:** XXXX\n",
    "\n",
    "**Author 1 (sciper):** XXXX (XXXXXX)  \n",
    "**Author 2 (sciper):** XXXX (XXXXXX)   \n",
    "**Author 3 (sciper):** XXXX (XXXXXX)  \n",
    "\n",
    "**Release date:** 24.03.2023  \n",
    "**Due date:** 07.04.2023 (11:59 pm)\n",
    "\n",
    "\n",
    "## Important notes\n",
    "\n",
    "The lab assignments are designed to teach practical implementation of the topics presented during class well as\n",
    "preparation for the final project, which is a practical project which ties together the topics of the course.\n",
    "\n",
    "As such, in the lab assignments/final project, unless otherwise specified, you may, if you choose, use external\n",
    "functions from image processing/ML libraries like opencv and sklearn as long as there is sufficient explanation\n",
    "in the lab report. For example, you do not need to implement your own edge detector, etc.\n",
    "\n",
    "**! Before handling back the notebook <font color='red'> rerun </font>the notebook from scratch !**\n",
    "`Kernel` > `Restart & Run All`\n",
    "\n",
    "We will not rerun the notebook for you.\n",
    "\n",
    "\n",
    "[iapr]: https://github.com/LTS5/iapr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M313pak5SmGi"
   },
   "source": [
    "---\n",
    "## 0. Extract relevant data\n",
    "We first need to extract the `lab-02-data.tar.gz` archive.\n",
    "To this end, we use the [tarfile] module from the Python standard library. In the `lab-02-data` folder, you will find 28x28 grey-scale pictures of handwritten \"0\", \"1\", \"2\" and \"3\".\n",
    "These digits have been extracted from MNIST dataset (http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "[tarfile]: https://docs.python.org/3.6/library/tarfile.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yeja8DMQSmGk"
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "data_base_path = os.path.join(os.pardir, 'data')\n",
    "data_folder = 'lab-02-data'\n",
    "data_part1 = os.path.join(data_base_path, data_folder, 'part1')\n",
    "data_part2 = os.path.join(data_base_path, data_folder, 'part2')\n",
    "\n",
    "tar_path = os.path.join(data_base_path, data_folder + '.tar.gz')\n",
    "with tarfile.open(tar_path, mode='r:gz') as tar:\n",
    "    tar.extractall(path=data_base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kYsGqDm2SmGo"
   },
   "source": [
    "### 0.1.Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wwZJcmXFSmGp",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def load(path, digit='0'):\n",
    "    digit_path = os.path.join(path, digit)\n",
    "    digit_names = [nm for nm in os.listdir(digit_path) if '.png' in nm]  # make sure to only load .png\n",
    "    digit_names.sort()  # sort file names\n",
    "    ic = skimage.io.imread_collection([os.path.join(digit_path, nm) for nm in digit_names])\n",
    "    digit_im = skimage.io.concatenate_images(ic)\n",
    "    return digit_im, digit_names\n",
    "                        \n",
    "# Load digits data\n",
    "\n",
    "# Zero images arrays\n",
    "zeros_im, zeros_names = load(data_part1, digit='0')\n",
    "# Ones images arrays\n",
    "ones_im, ones_names = load(data_part1, digit='1')\n",
    "# Twos images arrays\n",
    "twos_im, twos_names = load(data_part2, digit='2')\n",
    "# Threes images arrays\n",
    "threes_im, threes_names = load(data_part2, digit='3')\n",
    "\n",
    "# Plot images\n",
    "fig, axes = plt.subplots(4, len(zeros_im), figsize=(20, 8))\n",
    "for ax, im, nm in zip(axes[0], zeros_im, zeros_names):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n",
    "for ax, im, nm in zip(axes[1], ones_im, ones_names):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n",
    "for ax, im, nm in zip(axes[2], twos_im, twos_names):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n",
    "for ax, im, nm in zip(axes[3], threes_im, threes_names):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mpWlhTRnSmGn"
   },
   "source": [
    "---\n",
    "## Part 1 - contour based descriptors (18 pts)\n",
    "\n",
    "In this part you will use images of \"0\"s and \"1\"s.\n",
    "\n",
    "**Objectives overview**: Fourier Descriptors\n",
    "\n",
    "\n",
    "**1)** *Preprocess*: Select ONLY \"0\" and \"1\" images and apply suitable preprocessing. Show a plot with the preprocessed data and give arguments on the chosen techniques. (**2 pts**)\n",
    "\n",
    "\n",
    "**2)** *Get descriptors*: Find the contours and get the Fourier descriptors in complex definition. *Note*: The contours arrays should contain a finite number (N-> self-chosen) of equi-distant points for each image (hint: interpolation). In the case of the \"0\" contours, just keep the outermost contour. Discuss the necessity of this format. (**4 pts**)\n",
    "    \n",
    "    \n",
    "**3)** *Study effect of descriptors* : Show the contour-reconstruction of the digits using different amount of descriptors (both for ONE \"0\" image and ONE \"1\" image)\n",
    "- Make 5 plots, reconstructing the digits' countours using different amounts of descriptors. (e.g. reconstruct the contour using the only the 1st fourier descriptor, reconstruct using the first two fourier descriptors,  using the first three ...)  \n",
    "- **Hint**: check scipy fft, ifft, and fftfreq functions (see [link](https://docs.scipy.org/doc/scipy/tutorial/fft.html)) and pay attention on the ordering, observing which coefficients correspond to positive/negative frequencies of components and how you choose your low frequency subsets . \n",
    "- **Extra hint** To reconstruct the contour, copy the original vector of the fourier descriptors, keep the positive an negative frequencies you will use, and set to 0 the rest. (e.g. If you want to reconstruc the image with the first _three fourier descriptors_, keep the first _three positive frecuencies_ and their respective _three negative frequencies_ (see positive and negative bin freque\n",
    "    frequencies [link](https://docs.scipy.org/doc/scipy/reference/generated/scipy.fft.fftfreq.html#scipy.fft.fftfreq) ). \n",
    "- Discuss about your findings. (**4 pts**)\n",
    "    \n",
    "        \n",
    "**4)** *Clustering*: For each image containing a \"0\" or a \"1\", using the fourier descriptors, extract a 2-dimensional feature vector (using the THE POSITIVE bin frequencies from fftfreq, see [link](https://docs.scipy.org/doc/scipy/reference/generated/scipy.fft.fftfreq.html#scipy.fft.fftfreq) ) and plot all of them on a 2D graph. Did you obtain a plot where the vectors of the \"0\"'s nicely cluster in one part of the plane and those of the \"1\"'s in the other? If yes, explain why. (**2 pts**)\n",
    "    \n",
    "    \n",
    "**5)** *Show translation, rotation and scale invariance*\n",
    "- Firstly, discuss which descriptors, or which part of the descriptors are affected by each transformation. For each transformation define (write in words) an operation which will be applied to the descriptor arrays, such that they will be invariant to (not affected by) the specific transformation anymore. After finding the necessary operations, define a function that will make the Fourier descriptors invariant to all the transformations, altogether.(**3 pts**) \n",
    "- Secondly, show that if you are using descriptors invariant to transformations, you still obtain 2 nicely defined clusters for the 2 categories of numbers, under transformations applied. (You need to define custom functions for each transformation, apply them on images, and compare the obtained invariant descriptors). Discuss your findings. (**3 pts**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dUMViQWYIa1l"
   },
   "source": [
    "### 1. Fourier Descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsoAfO-jIa1l"
   },
   "source": [
    "### 1.1. Preprocess and visualization (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WGa7RuviIa1l"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1n8r-exRIa1m",
    "outputId": "73ce8f06-ec49-4c02-be3e-ce08954bb6a0"
   },
   "outputs": [],
   "source": [
    "# TODO: Fill the lists below with your preprocessed images of \"0\"s and \"1\"s  \n",
    "zeros = []\n",
    "ones = []\n",
    "\n",
    "# Plot images\n",
    "fig, axes = plt.subplots(2, len(zeros), figsize=(12, 3))\n",
    "for ax, im, nm in zip(axes[0], zeros, zeros_names):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n",
    "for ax, im, nm in zip(axes[1], ones, ones_names):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n",
    "fig.suptitle(\"Preprocessed images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flIcIulQSmGs"
   },
   "source": [
    "#### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSyYPFDrIa1n"
   },
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYSk6xjrSmGq"
   },
   "source": [
    "### 1.2. Get descriptors (4 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0GqguTVSmGt"
   },
   "outputs": [],
   "source": [
    "# Function that takes as input an image and returns a set of descriptors. \n",
    "# You may use other custom helper functions to break the code into useful chuncks.\n",
    "\n",
    "# TODO\n",
    "\n",
    "def get_descriptors(img):\n",
    "    descriptors = []\n",
    "    # TODO\n",
    "    \n",
    "    return descriptors\n",
    "\n",
    "# Check first 10 descriptors of a test image (just to check that your pipeline works well)\n",
    "print(get_descriptors(zeros_im[0])[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2cUQEFDIa1n"
   },
   "source": [
    "#### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mfu8aQUVIa1o"
   },
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6KsOrYBnIa1o"
   },
   "source": [
    "### 1.3. Study effect of descriptors (6 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DQGFoAFcIa1o"
   },
   "outputs": [],
   "source": [
    "# Define increasing set sizes of the descriptors. You can also change these numbers.\n",
    "descr_set_sizes = [1, 2, 5, 10, 20]\n",
    "\n",
    "# Define images for which you will show the recovery. You can also change the indexes.\n",
    "zero = zeros_im[0]\n",
    "one = ones_im[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_c5Bh-JKIa1o"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5L2INY9qIa1o"
   },
   "outputs": [],
   "source": [
    "# On each of the 5 plots you will show the recovery for a \"0\" and a \"1\" (used the same axis for both a \"0\" and a \"1\").\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "\n",
    "# Plot recovery for a zero image\n",
    "for i in range(0,  5):\n",
    "    # TODO\n",
    "    axes[i].# TODO\n",
    "\n",
    "# Plot recovery for a one image\n",
    "for i in range(0,  5):\n",
    "     # TODO\n",
    "    axes[i].# TODO\n",
    "\n",
    "fig.suptitle(\"Recovery of the contours\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LJh2eu1Ia1p"
   },
   "source": [
    "#### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtDOcXSLIa1p"
   },
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TI2byeUMIa1p"
   },
   "source": [
    "### 1.4 Clustering (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1vMmWWOSIa1p"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IJ28nvPoIa1p"
   },
   "outputs": [],
   "source": [
    "# TODO: You should fill the lists below, with your features\n",
    "\n",
    "# First feature for all \"0\"s\n",
    "zeros_f1 = []\n",
    "# Second feature for all \"0\"s\n",
    "zeros_f2 = []\n",
    "# Fist feature for all \"1\"s\n",
    "ones_f1 = []\n",
    "# Second feature for all \"1\"s\n",
    "ones_f2 = []\n",
    "\n",
    "# Plot features for all images\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.scatter(zeros_f1, zeros_f2, color='r', label='zeros')\n",
    "ax.scatter(ones_f1, ones_f2, color='b', label='ones')\n",
    "ax.legend(loc='best')\n",
    "plt.title(\"Features based on 2 Fourier descriptors\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o17jvjJgSmGu"
   },
   "source": [
    "#### Discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1PGKnUMeIa1q"
   },
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvosSyDyIa1q"
   },
   "source": [
    "### 1.5 Transformation invariance (6 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GiMViCPlIa1q"
   },
   "source": [
    "#### Preliminary discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbZbjWWDIa1q"
   },
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9KMrdqevIa1q"
   },
   "source": [
    "#### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1SCK9R1BIa1q"
   },
   "outputs": [],
   "source": [
    "# TODO: Implement a function that takes as input an image and outputs \n",
    "# a set of features invariant to scale, rotation and translation, according to function boolean parameters.\n",
    "# You may use your functions defined in section 1.B.\n",
    "\n",
    "def get_invariant_features(img, inv_to_rotation=False, inv_to_translation=False, inv_to_scale=False):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rM-7YB8jSmGv"
   },
   "outputs": [],
   "source": [
    "# Define custom rotation function. You may add other parameters to the function.\n",
    "def random_rotate(img):\n",
    "    # TODO\n",
    "    pass\n",
    "\n",
    "# Define custom rotation function. You may add other parameters to the function.\n",
    "def random_translate(img):\n",
    "    # TODO\n",
    "    pass\n",
    "    \n",
    "# Define custom rotation function. You may add other parameters to the function.\n",
    "def random_scale(img):\n",
    "    # TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hGtIm8YHIa1r"
   },
   "outputs": [],
   "source": [
    "# We will define 4 sets of new images below\n",
    "\n",
    "# TODO: Apply only rotation for each \"0\" and \"1\" and store results below\n",
    "rotated_images_zeros = []\n",
    "rotated_images_ones = []\n",
    "\n",
    "# TODO: Apply only translation for each \"0\" and \"1\" and store results below\n",
    "translated_images_zeros = []\n",
    "translated_images_ones = []\n",
    "\n",
    "# TODO: Apply only scaling for each \"0\" and \"1\" and store results below\n",
    "scaled_images_zeros = []\n",
    "scaled_images_ones = []\n",
    "\n",
    "# TODO: Apply all 3 transformations sequentially, in your custom order, for each \"0\" and \"1\" and store results below\n",
    "transformed_images_zeros = []\n",
    "transformed_images_ones = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g5gBHBZNIa1r"
   },
   "outputs": [],
   "source": [
    "# For each of the 4 sets of \"0\"s and \"1\"s above, you should find the invaiant features\n",
    "# and make a plot (similar to section 1.4) - 4 plots in total!\n",
    "# Use a proper labeling/legend for the plots!\n",
    "\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SwXYAya3SmGx"
   },
   "source": [
    "#### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8AsywMWIa1r"
   },
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fsqzRcUIa1r"
   },
   "source": [
    "## PART 2 - region based descriptors (10 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xqbxtS5rIa1s"
   },
   "source": [
    "In this part, you will use the \"2\"s and \"3\"s images.\n",
    "\n",
    "**Objectives overview**:\n",
    "\n",
    "**1)** *Cluster on compacity*: Based on custom definitions of perimeter and area for each image of \"2\" and \"3\" (preprocessed - by you), make a 2D plot with 2-dimensional feature vectors, similar to section 1.4. After that, define the compacity feature for each \"2\"s and \"3\"s image. Are you still able to obtain a 1D plot with values clustered in 2 well-defined regions? Discuss your findings. (**6 pts**).\n",
    "\n",
    "**2)** *Additional method*: Choose one more region-based method (from the course or your own sources - internet allowed) and redo the 1D plot in section 2.1 (or 2D plot, depending on your choosing). Explain your method and your findings. (**4 pts**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6XdedutIa1s"
   },
   "source": [
    "### 2.3. Cluster on compacity (6 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZZN3KlLIa1s"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDf7Zq-8Ia1s"
   },
   "outputs": [],
   "source": [
    "# TODO: Fill the arrays below with the perimeter and area as features for \"2\"s and \"3\"s images\n",
    "twos_f1 = []\n",
    "twos_f2 = []\n",
    "threes_f1 = []\n",
    "threes_f2 = []\n",
    "\n",
    "# Plot features for all images\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.scatter(twos_f1, twos_f2, color='r', label='twos')\n",
    "ax.scatter(threes_f1, threes_f2, color='b', label='threes')\n",
    "ax.legend(loc='best')\n",
    "plt.title(\"Features based on perimeter and area\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_juxnl6eIa1s"
   },
   "outputs": [],
   "source": [
    "# TODO: Make the 1D plot of the compacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1qTyHWGIa1s"
   },
   "source": [
    "####  Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYeuWMPTIa1s"
   },
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOvoAQeLSmGy"
   },
   "source": [
    "### 2.2. Additional method (4 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sNYSj4_hIa1t"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JtSEy0AIa1t"
   },
   "source": [
    "#### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4BXjF6YIa1t"
   },
   "source": [
    "TODO"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
