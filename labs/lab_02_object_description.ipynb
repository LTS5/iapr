{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IAPR][iapr]: Lab 2 ‒  Object description\n",
    "\n",
    "**Group ID:** xx\n",
    "\n",
    "**Author 1 (sciper):** Student Name 1 (xxxxx)  \n",
    "**Author 2 (sciper):** Student Name 2 (xxxxx)   \n",
    "**Author 3 (sciper):** Student Name 3 (xxxxx)   \n",
    "\n",
    "**Release date:** 25.03.2022  \n",
    "**Due date:** 08.04.2022 (11:59 pm)\n",
    "\n",
    "\n",
    "## Important notes\n",
    "\n",
    "The lab assignments are designed to teach practical implementation of the topics presented during class well as\n",
    "preparation for the final project, which is a practical project which ties together the topics of the course.\n",
    "\n",
    "As such, in the lab assignments/final project, unless otherwise specified, you may, if you choose, use external\n",
    "functions from image processing/ML libraries like opencv and sklearn as long as there is sufficient explanation\n",
    "in the lab report. For example, you do not need to implement your own edge detector, etc.\n",
    "\n",
    "**! Before handling back the notebook <font color='red'> rerun </font>the notebook from scratch !**\n",
    "`Kernel` > `Restart & Run All`\n",
    "\n",
    "We will not rerun the notebook for you.\n",
    "\n",
    "\n",
    "[iapr]: https://github.com/LTS5/iapr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 0. Extract relevant data\n",
    "We first need to extract the `lab-02-data.tar.gz` archive.\n",
    "To this end, we use the [tarfile] module from the Python standard library.\n",
    "\n",
    "[tarfile]: https://docs.python.org/3.6/library/tarfile.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import time\n",
    "import tarfile\n",
    "import skimage\n",
    "import os\n",
    "from skimage import filters\n",
    "from skimage import morphology\n",
    "from skimage import measure\n",
    "from skimage import exposure\n",
    "from skimage import color\n",
    "from skimage.transform import rescale\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.filters.rank import gradient\n",
    "from skimage.morphology import disk\n",
    "from skimage.exposure import histogram, cumulative_distribution, equalize_hist\n",
    "from scipy import ndimage as ndi\n",
    "from PIL import Image\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import webcolors\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "data_base_path = os.path.join(os.pardir, 'data')\n",
    "data_folder = 'lab-02-data'\n",
    "data_part1 = os.path.join(data_base_path, data_folder, 'part1')\n",
    "data_part2 = os.path.join(data_base_path, data_folder, 'part2')\n",
    "\n",
    "tar_path = os.path.join(data_base_path, data_folder + '.tar.gz')\n",
    "with tarfile.open(tar_path, mode='r:gz') as tar:\n",
    "    tar.extractall(path=data_base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1\n",
    "In the `lab-02-data/part1` folder, you will find **28x28 grey-scale pictures** of handwritten \"0\" and \"1\".\n",
    "These digits have been extracted from MNIST dataset (http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "Your goal is to extract, from each of those images, a 2-dimensional feature vector (i.e. 2 features) and to plot them all on a 2D graph.\n",
    "If you have chosen good features, the vectors of the \"0\"'s should nicely cluster in one part of the plane and those of the \"1\"'s in another.\n",
    "\n",
    "Please try:\n",
    "1. Fourier Descriptors (15pts). \n",
    "    1. Implementation (10 pts).\n",
    "    2. **Showing invariance to rotation, translation and scaling (5 pts).**\n",
    "2. Additional method of your choice (5 pts)\n",
    "\n",
    "\n",
    "**Note: for the Fourier descriptors, the u_k signal has to be constructed by following the contour point after point. Some pre-processing (image binarization, possibly some Mathematical Morphology) might be useful.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def load(path, digit='0'):\n",
    "    digit_path = os.path.join(path, digit)\n",
    "    digit_names = [nm for nm in os.listdir(digit_path) if '.png' in nm]  # make sure to only load .png\n",
    "    digit_names.sort()  # sort file names\n",
    "    ic = skimage.io.imread_collection([os.path.join(digit_path, nm) for nm in digit_names])\n",
    "    digit_im = skimage.io.concatenate_images(ic)\n",
    "    return digit_im, digit_names\n",
    "                        \n",
    "#  Load zeros and ones\n",
    "zeros_im, zeros_names = load(data_part1, digit='0')\n",
    "ones_im, ones_names = load(data_part1, digit='1')\n",
    "numberOf_im = zeros_im.shape[0]\n",
    "\n",
    "# Plot images\n",
    "fig, axes = plt.subplots(2, len(zeros_im), figsize=(12, 3))\n",
    "for ax, im, nm in zip(axes[0], zeros_im, zeros_names):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n",
    "for ax, im, nm in zip(axes[1], ones_im, ones_names):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot multiple images\n",
    "def plotMultipleImages(nrows, ncols, images, titles, cmap, figsize_x=14, figsize_y=7, suptitle=None):\n",
    "    fig = plt.figure(figsize=(figsize_x,figsize_y))\n",
    "    fig.suptitle(t=suptitle, y=0.63)\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.3)\n",
    "    for i in range(len(titles)):\n",
    "        ax = fig.add_subplot(nrows, ncols, i+1)\n",
    "        if cmap[i]=='rgb':\n",
    "            ax.imshow(images[i])\n",
    "        else:\n",
    "            ax.imshow(images[i], cmap=cmap[i])\n",
    "        ax.set_title(titles[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Fourier descriptors (15 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Preprocessing\n",
    "\n",
    "Input image must be segmented and boundary of the object must be found out before calculating the Fourier Descriptors. Thus, appropriate image preprocessing methods are considered. \n",
    "- A low-pass filter should be used to filter out unnecessary informations that may lead to misclassification of numbers. Here, we select the `median filter` due to its main advantages: I) Median filtering preserves sharp contours which are quite important bases in Fourier descriptors, whereas linear low-pass filtering blurs such edges. II) Median filters are very efficient for smoothing of spiky noise.\n",
    "- We check the histogram distribution of input image and found it is nicely bimodal. The two peaks (intensities of 0 and 255) correspond to the background and handwritten digits, and a few pixels lie in the range between 0 and 255. We then binariz the input images with thresholding to select areas of interest of images (here the digits). Because the input images are in different histrogram ditributions, a global threholding might not be good in all cases. Here, we use `Otsu's method` which determines an optimal global threshold value from the image histogram automatically.\n",
    "- After that, we use `morphological opening` to remove some white patches caused by residual noise (can be found in 1_8.png).\n",
    "- Finally, function `find_countours` is used to detect the contours of objects. And the returned value is a list of the coordinates of the contour pixels in order, going **counterclocwise** around the shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test image\n",
    "ind = 7\n",
    "test_im = ones_im[ind]\n",
    "test_im_name = ones_names[ind]\n",
    "\n",
    "# check the histrogram ditribution\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(test_im, cmap='gray')\n",
    "ax[0].set_title(test_im_name)\n",
    "ax[0].axis('off') \n",
    "ax[1].hist(test_im.ravel(), bins=256) \n",
    "ax[1].set_title('256 bins historgram of '+test_im_name)\n",
    "ax[1].set_xlabel('Pixel intensity')\n",
    "ax[1].set_ylabel('Number of pixels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ordered_contour(in_im):\n",
    "    # a list of the coordinates of the contour pixels (float type)\n",
    "    \n",
    "    contours = measure.find_contours(in_im, 5)\n",
    "    ordered_contour = []\n",
    "    contour_im = np.zeros(in_im.shape).astype(np.uint8)\n",
    "    contour_len = []\n",
    "    for contour in contours:\n",
    "        contour_len.append(contour.shape[0])\n",
    "        contour = np.rint(contour).astype(np.uint8)\n",
    "        for x,y in contour:\n",
    "            ordered_contour.append((x,y))\n",
    "            contour_im[x,y] = 255\n",
    "    #print(contour_len)\n",
    "    return np.array(ordered_contour).astype(int), contour_im\n",
    "\n",
    "def pre_processing(in_im, thresh=5):\n",
    "    # De-noise\n",
    "    # median filter with kernel = 1\n",
    "    \n",
    "    median_im = cv.medianBlur(in_im, 1)\n",
    "\n",
    "    # Image binarization\n",
    "    # Otsu's thresholding\n",
    "    _,binary_im = cv.threshold(median_im, 0, 255, cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "\n",
    "    # Morphological opening\n",
    "    morph_im = skimage.morphology.diameter_opening(binary_im,thresh)\n",
    "    \n",
    "    # get the orderred contours\n",
    "    ordered_contour, contour_im = get_ordered_contour(morph_im)\n",
    "    \n",
    "    return median_im, binary_im, morph_im, contour_im, ordered_contour\n",
    "\n",
    "def collect_contours_forAll(numberOf_im, zeros_im, ones_im, thresh=5):\n",
    "    # compute the contour coordinates\n",
    "    zeros_contour = []\n",
    "    ones_contour = []\n",
    "    zeros_contour_im = np.zeros(zeros_im.shape).astype(np.uint8)\n",
    "    ones_contour_im = np.zeros(ones_im.shape).astype(np.uint8)\n",
    "    for ind, zeros, ones in zip(range(numberOf_im), zeros_im, ones_im):\n",
    "        _, _, _, contour_im, ordered_contour = pre_processing(zeros)\n",
    "        zeros_contour_im[ind] = contour_im\n",
    "        zeros_contour.append(ordered_contour)\n",
    "        _, _, _, contour_im, ordered_contour = pre_processing(ones, thresh)\n",
    "        ones_contour_im[ind] = contour_im\n",
    "        ones_contour.append(ordered_contour)\n",
    "    return zeros_contour, ones_contour, zeros_contour_im, ones_contour_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_contour, ones_contour, zeros_contour_im, ones_contour_im = collect_contours_forAll(numberOf_im, zeros_im, ones_im)\n",
    "# display the plots\n",
    "plotMultipleImages(1, 10, zeros_im, zeros_names, cmap=['gray']*10, figsize_x=20, figsize_y=10,suptitle='Zeros images')\n",
    "plotMultipleImages(1, 10, zeros_contour_im, zeros_names, cmap=['gray']*10, figsize_x=20, figsize_y=10, suptitle='Contours of Zeros images')\n",
    "plotMultipleImages(1, 10, ones_im, ones_names, cmap=['gray']*10, figsize_x=20, figsize_y=10,suptitle='Ones images')\n",
    "plotMultipleImages(1, 10, ones_contour_im, ones_names, cmap=['gray']*10, figsize_x=20, figsize_y=10, suptitle='Contours of Ones images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Implementation of Fourier descriptors\n",
    "\n",
    "Fourier descriptors are a way of encoding the shape of a two-dimensional object by taking the Fourier transform of the boundary, where every  point on the boundary is mapped to a complex number. Let $(x_n, y_n)$ be the coordinates of the $n^{th}$ pixel on the contour of a given 2D shape, a complex number can be formed as: $C_n = x_n + j*y_n$. Now the Fourier Descriptors are calculated by combining complex array Fourier transform coefficients $C_0,C_1,C_2,......,C_{N-1}$. Thus, the following steps are followed:\n",
    "- We firstly represent the `zeros_contour` and `ones_contour` obtained in previous part as an array of such complex numbers which corresponds to the pixels of the object if the image is placed in the complex plane.\n",
    "- Then the pre-existing function `fft` in numpy is used to compute the Fourier descriptors $(F_0, F_1,...,F_{N-1})$. Users can select the first N descriptors which contain the majority of the shape information of the object as the results. \n",
    "- Because the first descriptor $F_0$ (\"DC-component\") of Fourier transform gives the average power of whole signal and is quite sensitive to the translation. Hence, we decided to truncate it to ensure location-invariance and select Fourier descriptors only from $F_1, F_2,...,F_{N-1}$.\n",
    "- The fourier descriptors are complex here, thus we take their amplitudes as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index of selected fourier descriptors: start, start+1, ..., start+N-1\n",
    "def get_Fourier_descriptors(real_contour, start=1, N=2, scale=None):\n",
    "    complex_contour = np.zeros(real_contour.shape[0], dtype=complex)\n",
    "    complex_contour.real = real_contour[:,0]\n",
    "    complex_contour.imag = real_contour[:,1]\n",
    "    \n",
    "    descriptors = np.fft.fft(complex_contour)\n",
    "    \n",
    "    if scale:\n",
    "        features = np.abs(descriptors[start:start+N])/np.abs(descriptors[1])\n",
    "    else:\n",
    "        features = np.abs(descriptors[start:start+N])\n",
    "        \n",
    "    return features\n",
    "\n",
    "def get_features(zeros_contour, ones_contour, start=1, N=2, scale=None):\n",
    "    \n",
    "    zeros_features = []\n",
    "    ones_features = []\n",
    "    \n",
    "    for zeros, ones in zip(zeros_contour, ones_contour):\n",
    "        features = get_Fourier_descriptors(zeros, start, N, scale)\n",
    "        zeros_features.append(features)\n",
    "        features = get_Fourier_descriptors(ones, start, N, scale)\n",
    "        ones_features.append(features)\n",
    "        \n",
    "    return np.array(zeros_features), np.array(ones_features)\n",
    "\n",
    "def plot_features(zeros_features, ones_features, annote=None, title=None, plt_ax=None):\n",
    "    if not plt_ax:\n",
    "        plot_method= plt\n",
    "        plt.xlabel('Amplitude of descriptor 1')\n",
    "        plt.ylabel('Amplitude of descriptor 2')\n",
    "    else:\n",
    "        plot_method = plt_ax\n",
    "        plot_method.set_xlabel('Amplitude of descriptor 1')\n",
    "        plot_method.set_ylabel('Amplitude of descriptor 2')\n",
    "    \n",
    "    plot_method.scatter(zeros_features[:,0], zeros_features[:,1], label='digit 0')\n",
    "    plot_method.scatter(ones_features[:,0], ones_features[:,1], label='digit 1')\n",
    "    if annote:\n",
    "        annote_text = [str(i) for i in range(10)]\n",
    "        for text, zeros, ones in zip(annote_text, zeros_features, ones_features):\n",
    "            plot_method.annotate(text, (zeros[0],zeros[1]), textcoords=\"offset points\",\n",
    "                         xytext=(0,10),\n",
    "                         ha='center')\n",
    "            plot_method.annotate(text, (ones[0],ones[1]), textcoords=\"offset points\",\n",
    "                         xytext=(0,10), \n",
    "                         ha='center')\n",
    "    if title:\n",
    "        if not plt_ax:\n",
    "            plt.title(title)\n",
    "        else:\n",
    "            plot_method.set_title(title)\n",
    "            \n",
    "    plot_method.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take features\n",
    "zeros_features, ones_features = get_features(zeros_contour, ones_contour)\n",
    "plot_features(zeros_features, ones_features, annote=True, title='Feature space of digit clusters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the figure above, both digit clusters are well classified by using only two features of Fourier descriptors. It is possible to seperate these two clusters by using a simple linear classifier due to their high inter-variance. Additionally, the Fourier descriptors can capture the intra-variance for each cluster well. From raw images, we can see that most digit-1 objects (except for 1_5.png and 1_9.png) have similar contours, which means that the digit-1 cluster has a small intra-variance and thus it gives a compact form in feature space. For digit-0 cluster, due to the inconsistent written formats of digit-0 objects, it has a high intra-variance and thus it gives a sparse form in feature space, for example, slender 0s (i.e., 0_4.png and 0_9.png) give much lower energy in Fourier descriptors than those fat 0s (i.e., 0_5.png and 0_7.png), and 0_8.png becomes a outlier in feature space because it has much more contours than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 Properties of Fourier descriptor\n",
    "In this section, rotation, translation and scaling are applied on raw images to check if Fourier descriptor is robust to image transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.3.1 Rotation invariance\n",
    "By Image rotation, the image is rotated about its center by specified number of degrees $(\\theta)$, which can be defined by constructing a matrix in the form: $\\begin{bmatrix} \\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta \\end{bmatrix}$. Idealized rotation for the angle $(\\theta)$ can be expressed as multiplication of the every element in the Fourer descriptors array with $e^{\\theta{i}}$ . The discrete Fourier transform of such an array can be given as: $e^{\\theta{i}}F_1, e^{\\theta{i}}F_2,...,e^{\\theta{i}}F_{N-1}$. Thus, for attaining the rotational invariance it is enough to take the absolute value of each descriptor, because $|e^{\\theta{i}}| = 1$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(raw_im, degree = 45):\n",
    "    '''\n",
    "        To rotate image with certain degrees. \n",
    "        Degree is positive for anti-clockwise and negative for clockwise.\n",
    "        \n",
    "        Input: grayscale image, rotation degrees. \n",
    "        Output: rotated grayscale image. \n",
    "    '''\n",
    "    # get the dimensions of the image\n",
    "    (height, width) = raw_im.shape\n",
    "    # calculate the center of the image\n",
    "    center = (width // 2, height // 2)\n",
    "    # get a rotation mask\n",
    "    mask = cv.getRotationMatrix2D(center, degree, 1.0)\n",
    "    # rotate the image\n",
    "    rotated_im = cv.warpAffine(src=raw_im, M=mask, dsize=(width,height))\n",
    "    \n",
    "    return rotated_im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the rotate_image function on images\n",
    "zeros_rotate_im = np.zeros(zeros_im.shape).astype(np.uint8)\n",
    "ones_rotate_im = np.zeros(ones_im.shape).astype(np.uint8)\n",
    "degrees = [20, 40, 60]\n",
    "fig, axes = plt.subplots(2, 2, sharex=True, sharey=True, figsize=(15,8))\n",
    "ax = axes.ravel()\n",
    "zeros_features, ones_features = get_features(zeros_contour, ones_contour)\n",
    "plot_features(zeros_features, ones_features, annote=True, title='Original feature space of digit clusters', plt_ax=ax[0])\n",
    "for i, degree in enumerate(degrees):\n",
    "    for ind, zeros, ones in zip(range(numberOf_im), zeros_im, ones_im):\n",
    "        zeros_rotate_im[ind] = rotate_image(zeros, degree)\n",
    "        ones_rotate_im[ind] = rotate_image(ones, degree)\n",
    "    zeros_rotate_contour, ones_rotate_contour, _ , _ = collect_contours_forAll(numberOf_im, zeros_rotate_im, ones_rotate_im)\n",
    "    zeros_rotate_features, ones_rotate_features = get_features(zeros_rotate_contour, ones_rotate_contour)\n",
    "    plot_features(zeros_rotate_features, ones_rotate_features, annote=True, title='Feature space of digit clusters with {0} degrees rotation'.format(degree), plt_ax=ax[i+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we use the absolute values of the Fourier descriptors, rotation invariance is already present. Rotation of the contour is simply a phase shift, which does not factor into the absolute value. In order to demonstrate this, the images are rotated by random degrees and their fourier descriptors are displayed again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.3.2 Translation invariance\n",
    "Translation refers to the rectilinear shift of an object i.s. an image from one location to another. If we know the amount of shift in horizontal and the vertical direction, say $(t_x, t_y)$ then we make a transformation matrix e.g. $\\begin{bmatrix} 1 & 0 & t_x \\\\ 0 & 1 & t_y \\end{bmatrix}$. According to the theory [1], the translation affects only the value of discrete Fourier transform’s first element, and the translation invariance can be acquired just by truncating the first element $F_0$. Thus, we use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_image(raw_im, tx, ty):\n",
    "    '''\n",
    "        To translate image with distances tx, ty. \n",
    "        \n",
    "        Input: grayscale image, translation distance. \n",
    "        Output: translated grayscale image. \n",
    "    '''\n",
    "    # get the dimensions of the image\n",
    "    (height, width) = raw_im.shape\n",
    "    # get a translation mask\n",
    "    mask = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "    # translate the image\n",
    "    translate_im = cv.warpAffine(src=raw_im, M=mask, dsize=(width,height))\n",
    "    \n",
    "    return translate_im.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test image\n",
    "ind = 8\n",
    "test_im = zeros_im[ind]\n",
    "translate_dist = [2, 3]\n",
    "test_translate_im = translate_image(test_im, translate_dist[0], translate_dist[1])\n",
    "images = [test_im, test_translate_im]\n",
    "title = ['ori', 'tra']\n",
    "plotMultipleImages(1, 2, images, title, cmap=['gray']*2, figsize_x=10, figsize_y=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use conservative translation distances because a significant translation might cause parts of image objects to be cropped/hidden (i.e. out of scene) which will definitely change the Fourier descriptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the translate_image function on images\n",
    "zeros_translate_im = np.zeros(zeros_im.shape).astype(np.uint8)\n",
    "ones_translate_im = np.zeros(ones_im.shape).astype(np.uint8)\n",
    "translate_dists = [[2, 3], [-2, -3], [-4, 4]]\n",
    "fig, axes = plt.subplots(2, 2, sharex=True, sharey=True, figsize=(15,8))\n",
    "ax = axes.ravel()\n",
    "zeros_features, ones_features = get_features(zeros_contour, ones_contour)\n",
    "plot_features(zeros_features, ones_features, annote=True, title='Original feature space of digit clusters', plt_ax=ax[0])\n",
    "for i, translate_dist in enumerate(translate_dists):\n",
    "    for ind, zeros, ones in zip(range(numberOf_im), zeros_im, ones_im):\n",
    "        zeros_translate_im[ind] = translate_image(zeros, translate_dist[0], translate_dist[1])\n",
    "        ones_translate_im[ind] = translate_image(ones, translate_dist[0], translate_dist[1])\n",
    "    zeros_translate_contour, ones_translate_contour, _ , _ = collect_contours_forAll(numberOf_im, zeros_translate_im, ones_translate_im)\n",
    "    zeros_translate_features, ones_translate_features = get_features(zeros_translate_contour, ones_translate_contour)\n",
    "    plot_features(zeros_translate_features, ones_translate_features, annote=True, title='Feature space of digit clusters with {0} translation distance'.format(translate_dist), plt_ax=ax[i+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.3.3 Scaling invariance\n",
    "Rescaling an image means changing the dimensions of it, be it width alone, height alone or changing both of them. Here we use `rescale` function from skimage library to resize an image by a given scaling factor. Idealized scaling can be expressed as multiplication of the every element in the array with the real constant $C$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test image\n",
    "ind = 9\n",
    "test_im = zeros_im[ind]\n",
    "scale_factors = [0.25, 0.5, 2, 4]\n",
    "test_scale_im_0 = (rescale(test_im, scale_factors[0], preserve_range=True, anti_aliasing=True))\n",
    "test_scale_im_1 = (rescale(test_im, scale_factors[1], preserve_range=True, anti_aliasing=True))\n",
    "test_scale_im_2 = (rescale(test_im, scale_factors[2], preserve_range=True)).astype(np.uint8)\n",
    "test_scale_im_3 = (rescale(test_im, scale_factors[3], preserve_range=True)).astype(np.uint8)\n",
    "images = [test_im, test_scale_im_0, test_scale_im_1, test_scale_im_2, test_scale_im_3]\n",
    "title = ['ori', 'tra_0', 'tra_1', 'tra_2', 'tra_3']\n",
    "plotMultipleImages(1, 5, images, title, cmap=['gray']*5, figsize_x=10, figsize_y=7)\n",
    "print(np.round(np.dot(test_im.shape,0.2)), test_scale_im_0.shape, test_scale_im_1.shape, test_scale_im_2.shape, test_scale_im_3.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_factors = [1, 0.5, 2, 4]\n",
    "threshs = [5, 5, 10, 20]\n",
    "fig, axes = plt.subplots(2, 2, sharex=False, sharey=False, figsize=(15,10))\n",
    "ax = axes.ravel()\n",
    "#zeros_features, ones_features = get_features(zeros_contour, ones_contour, start=2, N=2, scale=True)\n",
    "#plot_features(zeros_features, ones_features, annote=True, title='Original feature space of digit clusters', plt_ax=ax[0])\n",
    "for i, scale_factor in enumerate(scale_factors):\n",
    "    print('factor is ',scale_factor)\n",
    "    scale_shape = (10, int(28*scale_factor), int(28*scale_factor))\n",
    "    zeros_scale_im = np.zeros(scale_shape).astype(np.uint8)\n",
    "    ones_scale_im = np.zeros(scale_shape).astype(np.uint8)\n",
    "    for ind, zeros, ones in zip(range(numberOf_im), zeros_im, ones_im):\n",
    "        zeros_scale_im[ind] = rescale(zeros, scale_factor, preserve_range=True, anti_aliasing=False)\n",
    "        ones_scale_im[ind] = rescale(ones, scale_factor, preserve_range=True, anti_aliasing=False)\n",
    "    zeros_scale_contour, ones_scale_contour, _ , _ = collect_contours_forAll(numberOf_im, zeros_scale_im, ones_scale_im, thresh=threshs[i])\n",
    "    zeros_scale_features, ones_scale_features = get_features(zeros_scale_contour, ones_scale_contour, start=2, N=2, scale=True)\n",
    "    plot_features(zeros_scale_features, ones_scale_features, annote=True, title='Feature space of digit clusters with scale factor = {0}'.format(scale_factor), plt_ax=ax[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Additional method (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your implementation and discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2\n",
    "The `lab-02-data/part2` folder contains grey-scale pictures of handwritten \"2\" and \"3\".\n",
    "Extract the same feature (typically 2 Fourier descriptors) as in part 1 also on these images and plot them on the same graph as the features of the \"0\" and \"1\".\n",
    "Is it possible to discriminate all these 4 digits with a 2-dimensional feature vector?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load twos and threes\n",
    "twos_im, twos_names = load(data_part2, digit='2')\n",
    "threes_im, threes_names = load(data_part2, digit='3')\n",
    "\n",
    "# Plot images\n",
    "fig, axes = plt.subplots(2, len(twos_im), figsize=(12, 3))\n",
    "for ax, im, nm in zip(axes[0], twos_im, twos_names):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n",
    "for ax, im, nm in zip(axes[1], threes_im, threes_names):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Fourier descriptors - 4 digits (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your implementation and discussion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
